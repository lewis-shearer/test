{
  "cells": [
    {
      "metadata": {
        "id": "30e3009cfc0aeba1"
      },
      "cell_type": "markdown",
      "source": [
        "# Age and Gender Debiasing using UTKFace Dataset with W&B Grid Search\n",
        "\n",
        "This notebook implements a debiased age prediction model using adversarial training with W&B hyperparameter sweep using grid search.\n"
      ],
      "id": "30e3009cfc0aeba1"
    },
    {
      "metadata": {
        "id": "709c8f13c6d42699"
      },
      "cell_type": "markdown",
      "source": [
        "## ğŸ“š Import Required Libraries\n"
      ],
      "id": "709c8f13c6d42699"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-19T19:01:17.392104Z",
          "start_time": "2026-02-19T19:00:59.519610Z"
        },
        "id": "a515c1f1b96fa5c2"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import wandb\n",
        "try:\n",
        "    from wandb.keras import WandbCallback\n",
        "except ImportError:\n",
        "    from wandb.integration.keras import WandbCallback\n",
        "from tqdm import tqdm\n"
      ],
      "id": "a515c1f1b96fa5c2",
      "outputs": [],
      "execution_count": 2
    },
    {
      "metadata": {
        "id": "77d6f6bafbb634ee"
      },
      "cell_type": "markdown",
      "source": [
        "## ğŸ–¼ï¸ Load and Preprocess Images\n"
      ],
      "id": "77d6f6bafbb634ee"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-19T19:01:38.565707Z",
          "start_time": "2026-02-19T19:01:17.398411Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b29f0f005f7bd420",
        "outputId": "9d3e8c3b-afc8-4b3c-8283-6c13a916c6d5"
      },
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jangedoo/utkface-new\")\n",
        "print(\"Path to dataset files:\", path)\n"
      ],
      "id": "b29f0f005f7bd420",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'utkface-new' dataset.\n",
            "Path to dataset files: /kaggle/input/utkface-new\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-19T19:02:47.378842Z",
          "start_time": "2026-02-19T19:01:39.389248Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52c87a50a657c084",
        "outputId": "648a2109-df4c-4eb6-fb15-7123430c046c"
      },
      "cell_type": "code",
      "source": [
        "# Dataset path\n",
        "data_dir = os.path.join(path, \"UTKFace\")\n",
        "\n",
        "# Lists to store data\n",
        "images, ages, genders, races = [], [], [], []\n",
        "\n",
        "for img_name in tqdm(os.listdir(data_dir)):\n",
        "    try:\n",
        "        # UTKFace filenames: [age]_[gender]_[race]_*.jpg\n",
        "        age, gender, race = img_name.split('_')[:3]\n",
        "        age, gender, race = int(age), int(gender), int(race)\n",
        "\n",
        "        img_path = os.path.join(data_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (96, 96))\n",
        "        images.append(img)\n",
        "        ages.append(age)\n",
        "        genders.append(gender)\n",
        "        races.append(race)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "# Convert to numpy arrays\n",
        "images = np.array(images)\n",
        "ages = np.array(ages)\n",
        "genders = np.array(genders)\n",
        "races = np.array(races)\n",
        "\n",
        "print(\"Total images loaded:\", len(images))\n",
        "print(\"Example labels:\", ages[0], genders[0], races[0])\n"
      ],
      "id": "52c87a50a657c084",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23708/23708 [00:25<00:00, 918.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images loaded: 23705\n",
            "Example labels: 26 0 2\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-19T19:02:48.068004Z",
          "start_time": "2026-02-19T19:02:47.559158Z"
        },
        "id": "9906ae53261b24ad"
      },
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Gradient Reversal Layer\n",
        "# -----------------------\n",
        "class GradientReversalLayer(Layer):\n",
        "    def __init__(self, alpha=1.0, **kwargs):\n",
        "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def call(self, x):\n",
        "        @tf.custom_gradient\n",
        "        def _flip_grad(x):\n",
        "            def grad(dy):\n",
        "                return -self.alpha * dy\n",
        "            return x, grad\n",
        "        return _flip_grad(x)\n"
      ],
      "id": "9906ae53261b24ad",
      "outputs": [],
      "execution_count": 5
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-19T19:02:49.363991Z",
          "start_time": "2026-02-19T19:02:48.786092Z"
        },
        "id": "b245d535c27030fc"
      },
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Helper function: Calculate MAE for each group\n",
        "# -----------------------\n",
        "def group_mae(true_labels, pred_labels, group_labels, group_names):\n",
        "    \"\"\"\n",
        "    Calculate MAE for each group.\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    true_labels = np.array(true_labels).flatten()\n",
        "    pred_labels = np.array(pred_labels).flatten()\n",
        "    group_labels = np.array(group_labels).flatten()\n",
        "\n",
        "    for group_id in np.unique(group_labels):\n",
        "        mask = group_labels == group_id\n",
        "        if np.sum(mask) > 0:\n",
        "            mae = mean_absolute_error(true_labels[mask], pred_labels[mask])\n",
        "            group_name = group_names.get(int(group_id), f\"Group_{group_id}\")\n",
        "            result[group_name] = float(mae)\n",
        "\n",
        "    return result\n"
      ],
      "id": "b245d535c27030fc",
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-19T19:02:53.789747Z",
          "start_time": "2026-02-19T19:02:50.762992Z"
        },
        "id": "d869699d9dffa992"
      },
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Prepare data (train/test split)\n",
        "# -----------------------\n",
        "X_train, X_test, age_train, age_test, gen_train, gen_test, race_train, race_test = train_test_split(\n",
        "    images, ages, genders, races, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# Reshape age labels\n",
        "age_train = np.array(age_train).reshape(-1, 1).astype('float32')\n",
        "age_test = np.array(age_test).reshape(-1, 1).astype('float32')\n",
        "\n",
        "# Process gender labels\n",
        "gen_train_arr = np.array(gen_train).astype(int)\n",
        "gen_test_arr = np.array(gen_test).astype(int)\n",
        "gen_train_cat = to_categorical(gen_train_arr, num_classes=2).astype('float32')\n",
        "gen_test_cat = to_categorical(gen_test_arr, num_classes=2).astype('float32')\n",
        "gen_train_labels = gen_train_arr\n",
        "gen_test_labels = gen_test_arr\n",
        "\n",
        "# Process race labels\n",
        "race_train_arr = np.array(race_train).flatten().astype(int)\n",
        "race_test_arr = np.array(race_test).flatten().astype(int)\n",
        "race_train_cat = to_categorical(race_train_arr, num_classes=5).astype('float32')\n",
        "race_test_cat = to_categorical(race_test_arr, num_classes=5).astype('float32')\n"
      ],
      "id": "d869699d9dffa992",
      "outputs": [],
      "execution_count": 7
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-19T19:03:04.296705Z",
          "start_time": "2026-02-19T19:02:54.864665Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "937d1fac4af82708",
        "outputId": "e010ad82-bc99-423b-a475-c2050326928a"
      },
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Preprocess images (resize + MobileNet preprocessing)\n",
        "# -----------------------\n",
        "def preprocess_images_for_mobilenet(X, target_size=(96, 96)):\n",
        "    X_tf = tf.convert_to_tensor(X, dtype=tf.float32)\n",
        "    X_resized = tf.image.resize(X_tf, target_size)\n",
        "    X_pre = preprocess_input(X_resized)\n",
        "    return X_pre.numpy()\n",
        "\n",
        "print(\"Preprocessing training images...\")\n",
        "X_train_pre = preprocess_images_for_mobilenet(X_train, target_size=(96, 96))\n",
        "\n",
        "print(\"Preprocessing test images...\")\n",
        "X_test_pre = preprocess_images_for_mobilenet(X_test, target_size=(96, 96))\n",
        "\n",
        "print(\"Prepared image shapes:\", X_train_pre.shape, X_test_pre.shape)\n",
        "print(\"Label shapes:\", age_train.shape, gen_train_cat.shape, race_train_cat.shape)\n"
      ],
      "id": "937d1fac4af82708",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing training images...\n",
            "Preprocessing test images...\n",
            "Prepared image shapes: (18964, 96, 96, 3) (4741, 96, 96, 3)\n",
            "Label shapes: (18964, 1) (18964, 2) (18964, 5)\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-19T19:03:08.368239Z",
          "start_time": "2026-02-19T19:03:05.656599Z"
        },
        "id": "41674b3bf9c01ea5"
      },
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# TRAINING FUNCTION FOR W&B SWEEP (STABLE VERSION)\n",
        "# -----------------------\n",
        "\n",
        "def train_with_sweep():\n",
        "\n",
        "    # Initialize W&B run (DO NOT specify project inside sweep)\n",
        "    run = wandb.init()\n",
        "    config = wandb.config\n",
        "\n",
        "    # Hyperparameters\n",
        "    batch_size = config.batch_size\n",
        "    learning_rate = config.learning_rate\n",
        "    dropout_rate = config.dropout_rate\n",
        "    adv_loss_weight = config.adv_loss_weight\n",
        "    n_unfreeze = config.n_unfreeze\n",
        "    reduce_lr_factor = config.reduce_lr_factor\n",
        "    reduce_lr_patience = config.reduce_lr_patience\n",
        "    early_stop_patience = config.early_stop_patience\n",
        "    weight_decay = config.weight_decay\n",
        "\n",
        "    total_epochs = 50\n",
        "    grl_alpha = 0.2\n",
        "    phase1_fraction = 0.7\n",
        "    phase1_epochs = int(total_epochs * phase1_fraction)\n",
        "    phase2_epochs = total_epochs - phase1_epochs\n",
        "\n",
        "    checkpoint_path = f\"best_model_{run.id}.keras\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Training with config:\")\n",
        "    print(dict(config))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # -----------------------\n",
        "    # BUILD MODEL\n",
        "    # -----------------------\n",
        "\n",
        "    input_layer = Input(shape=(96, 96, 3))\n",
        "\n",
        "    mobilenet_base = MobileNetV2(\n",
        "        input_shape=(96, 96, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    mobilenet_base.trainable = False\n",
        "\n",
        "    x = mobilenet_base(input_layer)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    concept = Dense(128, activation='relu', name='concept_layer')(x)\n",
        "    shared = Dropout(dropout_rate)(concept)\n",
        "\n",
        "    age_output = Dense(1, name='age_output')(shared)\n",
        "\n",
        "    grl_gender = GradientReversalLayer(alpha=grl_alpha)(concept)\n",
        "    gender_output = Dense(2, activation='softmax', name='gender_output')(grl_gender)\n",
        "\n",
        "    grl_race = GradientReversalLayer(alpha=grl_alpha)(concept)\n",
        "    race_output = Dense(5, activation='softmax', name='race_output')(grl_race)\n",
        "\n",
        "    dif_model_full = Model(\n",
        "        inputs=input_layer,\n",
        "        outputs=[age_output, gender_output, race_output]\n",
        "    )\n",
        "\n",
        "    dif_model_age_only = Model(\n",
        "        inputs=input_layer,\n",
        "        outputs=age_output\n",
        "    )\n",
        "\n",
        "    # -----------------------\n",
        "    # CALLBACKS (NO W&B CALLBACK)\n",
        "    # -----------------------\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=reduce_lr_factor,\n",
        "        patience=reduce_lr_patience,\n",
        "        verbose=1,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath=checkpoint_path,\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=early_stop_patience,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # -----------------------\n",
        "    # PHASE 1: AGE ONLY\n",
        "    # -----------------------\n",
        "\n",
        "    dif_model_age_only.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate, weight_decay=weight_decay),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    dif_model_age_only.fit(\n",
        "        X_train_pre, age_train,\n",
        "        validation_data=(X_test_pre, age_test),\n",
        "        epochs=phase1_epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[reduce_lr, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # -----------------------\n",
        "    # PHASE 1.5: WARMUP ADV HEADS\n",
        "    # -----------------------\n",
        "\n",
        "    temp_adv_model = Model(\n",
        "        inputs=input_layer,\n",
        "        outputs=[gender_output, race_output]\n",
        "    )\n",
        "\n",
        "    temp_adv_model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate, weight_decay=weight_decay),\n",
        "        loss={\n",
        "            'gender_output': 'categorical_crossentropy',\n",
        "            'race_output': 'categorical_crossentropy'\n",
        "        }\n",
        "    )\n",
        "\n",
        "    temp_adv_model.fit(\n",
        "        X_train_pre,\n",
        "        {'gender_output': gen_train_cat,\n",
        "         'race_output': race_train_cat},\n",
        "        epochs=5,\n",
        "        batch_size=batch_size,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # -----------------------\n",
        "    # PHASE 2: FULL ADVERSARIAL TRAINING\n",
        "    # -----------------------\n",
        "\n",
        "    mobilenet_base.trainable = True\n",
        "\n",
        "    if n_unfreeze > 0:\n",
        "        for layer in mobilenet_base.layers[:-n_unfreeze]:\n",
        "            layer.trainable = False\n",
        "        for layer in mobilenet_base.layers[-n_unfreeze:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    dif_model_full.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate * 0.5, weight_decay=weight_decay),\n",
        "        loss={\n",
        "            'age_output': 'mse',\n",
        "            'gender_output': 'categorical_crossentropy',\n",
        "            'race_output': 'categorical_crossentropy'\n",
        "        },\n",
        "        loss_weights={\n",
        "            'age_output': 1.0,\n",
        "            'gender_output': adv_loss_weight,\n",
        "            'race_output': adv_loss_weight\n",
        "        },\n",
        "        metrics={'age_output': 'mae'}\n",
        "    )\n",
        "\n",
        "    dif_model_full.fit(\n",
        "        X_train_pre,\n",
        "        {\n",
        "            'age_output': age_train,\n",
        "            'gender_output': gen_train_cat,\n",
        "            'race_output': race_train_cat\n",
        "        },\n",
        "        validation_data=(\n",
        "            X_test_pre,\n",
        "            {\n",
        "                'age_output': age_test,\n",
        "                'gender_output': gen_test_cat,\n",
        "                'race_output': race_test_cat\n",
        "            }\n",
        "        ),\n",
        "        epochs=phase2_epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[reduce_lr, checkpoint, early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # -----------------------\n",
        "    # EVALUATION\n",
        "    # -----------------------\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        dif_model_full.load_weights(checkpoint_path)\n",
        "\n",
        "    preds = dif_model_full.predict(X_test_pre, batch_size=batch_size, verbose=0)\n",
        "    pred_ages = np.array(preds[0]).flatten()\n",
        "\n",
        "    overall_mae = mean_absolute_error(age_test.flatten(), pred_ages)\n",
        "\n",
        "    gender_names = {0: 'male', 1: 'female'}\n",
        "    race_names = {0: 'White', 1: 'Black', 2: 'Asian', 3: 'Indian', 4: 'Others'}\n",
        "\n",
        "    gender_mae = group_mae(age_test, pred_ages, gen_test_labels, gender_names)\n",
        "    race_mae = group_mae(age_test, pred_ages, race_test_arr, race_names)\n",
        "\n",
        "    all_maes = list(gender_mae.values()) + list(race_mae.values())\n",
        "    worst_group_mae = max(all_maes)\n",
        "    mean_group_mae = np.mean(all_maes)\n",
        "    bias_gap = max(all_maes) - min(all_maes)\n",
        "\n",
        "    # -----------------------\n",
        "    # LOG METRICS\n",
        "    # -----------------------\n",
        "\n",
        "    wandb.log({\n",
        "        \"overall_mae\": overall_mae,\n",
        "        \"worst_group_mae\": worst_group_mae,\n",
        "        \"mean_group_mae\": mean_group_mae,\n",
        "        \"bias_gap\": bias_gap\n",
        "    })\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "    return worst_group_mae"
      ],
      "id": "41674b3bf9c01ea5",
      "outputs": [],
      "execution_count": 9
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-19T19:09:59.565402Z",
          "start_time": "2026-02-19T19:06:55.413947Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "d8bf4679338b2f4f",
        "outputId": "0123f0ef-8804-4200-cfe7-7c48968ef474"
      },
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# EXECUTE W&B SWEEP\n",
        "# -----------------------\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "        'name': 'worst_group_mae',\n",
        "        'goal': 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'batch_size': {'values': [16, 32]},\n",
        "        'learning_rate': {'values': [0.0001, 0.0005, 0.001]},\n",
        "        'dropout_rate': {'values': [0.25, 0.3, 0.35]},\n",
        "        'adv_loss_weight': {'values': [0.005, 0.01, 0.02]},\n",
        "        'n_unfreeze': {'values': [25, 30, 35]},\n",
        "        'reduce_lr_factor': {'values': [0.5]},\n",
        "        'reduce_lr_patience': {'values': [3]},\n",
        "        'early_stop_patience': {'values': [5]},\n",
        "        'weight_decay': {'values': [0.0001]}\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(\n",
        "    sweep_config,\n",
        "    project=\"age-gender-debiasing\"\n",
        ")\n",
        "\n",
        "print(\"Sweep ID:\", sweep_id)\n",
        "\n",
        "wandb.agent(\n",
        "    'ewgkcoz3',\n",
        "    function=train_with_sweep,\n",
        "    count=20\n",
        ")"
      ],
      "id": "d8bf4679338b2f4f",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 3javmb0y\n",
            "Sweep URL: https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/3javmb0y\n",
            "Sweep ID: 3javmb0y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e3ttcqgq with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_loss_weight: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stop_patience: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_unfreeze: 35\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treduce_lr_factor: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treduce_lr_patience: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlshearer2957\u001b[0m (\u001b[33mlshearer2957-self\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260219_203026-e3ttcqgq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/e3ttcqgq' target=\"_blank\">resilient-sweep-5</a></strong> to <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/e3ttcqgq' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/e3ttcqgq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training with config:\n",
            "{'adv_loss_weight': 0.01, 'batch_size': 32, 'dropout_rate': 0.3, 'early_stop_patience': 5, 'learning_rate': 0.001, 'n_unfreeze': 35, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 3, 'weight_decay': 0.0001}\n",
            "============================================================\n",
            "Epoch 1/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 297.7363 - mae: 12.8495\n",
            "Epoch 1: val_loss improved from inf to 159.11449, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 57ms/step - loss: 297.5901 - mae: 12.8463 - val_loss: 159.1145 - val_mae: 9.6965 - learning_rate: 0.0010\n",
            "Epoch 2/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 160.6113 - mae: 9.6034\n",
            "Epoch 2: val_loss improved from 159.11449 to 142.80302, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 160.6031 - mae: 9.6031 - val_loss: 142.8030 - val_mae: 8.8626 - learning_rate: 0.0010\n",
            "Epoch 3/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 146.6706 - mae: 9.1416\n",
            "Epoch 3: val_loss improved from 142.80302 to 138.22379, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 146.6840 - mae: 9.1416 - val_loss: 138.2238 - val_mae: 8.6973 - learning_rate: 0.0010\n",
            "Epoch 4/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 143.9729 - mae: 9.0908\n",
            "Epoch 4: val_loss improved from 138.22379 to 136.18933, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 143.9736 - mae: 9.0907 - val_loss: 136.1893 - val_mae: 8.6750 - learning_rate: 0.0010\n",
            "Epoch 5/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 142.9168 - mae: 8.9782\n",
            "Epoch 5: val_loss improved from 136.18933 to 134.72989, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 142.9115 - mae: 8.9780 - val_loss: 134.7299 - val_mae: 8.5296 - learning_rate: 0.0010\n",
            "Epoch 6/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 139.0786 - mae: 8.8613\n",
            "Epoch 6: val_loss improved from 134.72989 to 131.54027, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 139.0633 - mae: 8.8609 - val_loss: 131.5403 - val_mae: 8.5183 - learning_rate: 0.0010\n",
            "Epoch 7/35\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 134.1500 - mae: 8.7052\n",
            "Epoch 7: val_loss did not improve from 131.54027\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 134.1559 - mae: 8.7054 - val_loss: 136.5566 - val_mae: 8.5170 - learning_rate: 0.0010\n",
            "Epoch 8/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 133.1476 - mae: 8.6684\n",
            "Epoch 8: val_loss did not improve from 131.54027\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 133.1507 - mae: 8.6681 - val_loss: 133.6652 - val_mae: 8.6674 - learning_rate: 0.0010\n",
            "Epoch 9/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 132.6017 - mae: 8.5938\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 131.54027\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 132.6013 - mae: 8.5938 - val_loss: 136.4991 - val_mae: 8.8533 - learning_rate: 0.0010\n",
            "Epoch 10/35\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 124.9086 - mae: 8.3396\n",
            "Epoch 10: val_loss improved from 131.54027 to 130.67815, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 124.9008 - mae: 8.3397 - val_loss: 130.6781 - val_mae: 8.4362 - learning_rate: 5.0000e-04\n",
            "Epoch 11/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 120.7756 - mae: 8.2477\n",
            "Epoch 11: val_loss did not improve from 130.67815\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 120.8013 - mae: 8.2484 - val_loss: 131.8107 - val_mae: 8.3905 - learning_rate: 5.0000e-04\n",
            "Epoch 12/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 119.4875 - mae: 8.1785\n",
            "Epoch 12: val_loss improved from 130.67815 to 129.63023, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 119.5269 - mae: 8.1800 - val_loss: 129.6302 - val_mae: 8.3507 - learning_rate: 5.0000e-04\n",
            "Epoch 13/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 121.6627 - mae: 8.1890\n",
            "Epoch 13: val_loss did not improve from 129.63023\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 121.6623 - mae: 8.1891 - val_loss: 130.1198 - val_mae: 8.4704 - learning_rate: 5.0000e-04\n",
            "Epoch 14/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 119.0417 - mae: 8.1512\n",
            "Epoch 14: val_loss did not improve from 129.63023\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 119.0532 - mae: 8.1517 - val_loss: 131.0700 - val_mae: 8.4986 - learning_rate: 5.0000e-04\n",
            "Epoch 15/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 118.7798 - mae: 8.1592\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 129.63023\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 118.7833 - mae: 8.1593 - val_loss: 131.5233 - val_mae: 8.5595 - learning_rate: 5.0000e-04\n",
            "Epoch 16/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 115.6764 - mae: 8.0594\n",
            "Epoch 16: val_loss did not improve from 129.63023\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 115.6828 - mae: 8.0596 - val_loss: 129.8317 - val_mae: 8.4146 - learning_rate: 2.5000e-04\n",
            "Epoch 17/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 113.9149 - mae: 7.9831\n",
            "Epoch 17: val_loss did not improve from 129.63023\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 113.9187 - mae: 7.9832 - val_loss: 129.9566 - val_mae: 8.3412 - learning_rate: 2.5000e-04\n",
            "Epoch 18/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 116.2078 - mae: 8.0889\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 18: val_loss did not improve from 129.63023\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 116.1977 - mae: 8.0884 - val_loss: 130.6001 - val_mae: 8.3942 - learning_rate: 2.5000e-04\n",
            "Epoch 19/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 112.5778 - mae: 7.9432\n",
            "Epoch 19: val_loss did not improve from 129.63023\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 112.5834 - mae: 7.9433 - val_loss: 130.0861 - val_mae: 8.3318 - learning_rate: 1.2500e-04\n",
            "Epoch 20/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 111.8628 - mae: 7.8894\n",
            "Epoch 20: val_loss did not improve from 129.63023\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 111.8669 - mae: 7.8896 - val_loss: 129.7330 - val_mae: 8.3704 - learning_rate: 1.2500e-04\n",
            "Epoch 21/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 110.7168 - mae: 7.8298\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 129.63023\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 110.7295 - mae: 7.8304 - val_loss: 130.4272 - val_mae: 8.3544 - learning_rate: 1.2500e-04\n",
            "Epoch 22/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 114.4766 - mae: 7.9947\n",
            "Epoch 22: val_loss improved from 129.63023 to 129.40335, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 114.4748 - mae: 7.9948 - val_loss: 129.4034 - val_mae: 8.3583 - learning_rate: 6.2500e-05\n",
            "Epoch 23/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 113.6002 - mae: 7.9486\n",
            "Epoch 23: val_loss did not improve from 129.40335\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 113.5989 - mae: 7.9486 - val_loss: 129.5314 - val_mae: 8.3463 - learning_rate: 6.2500e-05\n",
            "Epoch 24/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 111.3704 - mae: 7.8793\n",
            "Epoch 24: val_loss did not improve from 129.40335\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 111.3719 - mae: 7.8794 - val_loss: 129.5570 - val_mae: 8.3722 - learning_rate: 6.2500e-05\n",
            "Epoch 25/35\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 110.5025 - mae: 7.9035\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 129.40335\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 110.5170 - mae: 7.9038 - val_loss: 129.6277 - val_mae: 8.3470 - learning_rate: 6.2500e-05\n",
            "Epoch 26/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 109.5554 - mae: 7.8393\n",
            "Epoch 26: val_loss did not improve from 129.40335\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 109.5635 - mae: 7.8395 - val_loss: 129.7240 - val_mae: 8.4016 - learning_rate: 3.1250e-05\n",
            "Epoch 27/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 113.6313 - mae: 7.9617\n",
            "Epoch 27: val_loss did not improve from 129.40335\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 113.6266 - mae: 7.9616 - val_loss: 129.4645 - val_mae: 8.3552 - learning_rate: 3.1250e-05\n",
            "Epoch 28/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 112.0560 - mae: 7.8690\n",
            "Epoch 28: val_loss improved from 129.40335 to 129.38901, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 112.0513 - mae: 7.8689 - val_loss: 129.3890 - val_mae: 8.3684 - learning_rate: 3.1250e-05\n",
            "Epoch 29/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 109.0015 - mae: 7.8469\n",
            "Epoch 29: val_loss did not improve from 129.38901\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 109.0039 - mae: 7.8469 - val_loss: 129.4840 - val_mae: 8.3556 - learning_rate: 3.1250e-05\n",
            "Epoch 30/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 110.4798 - mae: 7.8559\n",
            "Epoch 30: val_loss did not improve from 129.38901\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 110.4827 - mae: 7.8561 - val_loss: 129.4524 - val_mae: 8.3811 - learning_rate: 3.1250e-05\n",
            "Epoch 31/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 111.9665 - mae: 7.9372\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 31: val_loss did not improve from 129.38901\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 111.9470 - mae: 7.9361 - val_loss: 129.5500 - val_mae: 8.3419 - learning_rate: 3.1250e-05\n",
            "Epoch 32/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 112.9421 - mae: 7.8827\n",
            "Epoch 32: val_loss improved from 129.38901 to 129.38237, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 112.9370 - mae: 7.8830 - val_loss: 129.3824 - val_mae: 8.3677 - learning_rate: 1.5625e-05\n",
            "Epoch 33/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 113.4224 - mae: 7.9698\n",
            "Epoch 33: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 113.4101 - mae: 7.9693 - val_loss: 129.4727 - val_mae: 8.3731 - learning_rate: 1.5625e-05\n",
            "Epoch 34/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 111.2150 - mae: 7.9115\n",
            "Epoch 34: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 111.2126 - mae: 7.9113 - val_loss: 129.4303 - val_mae: 8.3692 - learning_rate: 1.5625e-05\n",
            "Epoch 35/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 110.7221 - mae: 7.8713\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 35: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 110.7206 - mae: 7.8712 - val_loss: 129.5093 - val_mae: 8.3623 - learning_rate: 1.5625e-05\n",
            "Epoch 1/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - gender_output_loss: 4.2368 - loss: 16.5336 - race_output_loss: 12.2967\n",
            "Epoch 2/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - gender_output_loss: 0.7551 - loss: 3.5548 - race_output_loss: 2.7997\n",
            "Epoch 3/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - gender_output_loss: 0.5891 - loss: 2.1256 - race_output_loss: 1.5366\n",
            "Epoch 4/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - gender_output_loss: 0.6012 - loss: 2.0074 - race_output_loss: 1.4062\n",
            "Epoch 5/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - gender_output_loss: 0.6286 - loss: 2.1109 - race_output_loss: 1.4824\n",
            "Epoch 1/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - age_output_loss: 2216.4043 - age_output_mae: 23.7900 - gender_output_loss: 0.6831 - loss: 2216.4255 - race_output_loss: 1.3965\n",
            "Epoch 1: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 48ms/step - age_output_loss: 2213.6450 - age_output_mae: 23.7722 - gender_output_loss: 0.6831 - loss: 2213.6667 - race_output_loss: 1.3965 - val_age_output_loss: 10981.4355 - val_age_output_mae: 92.5621 - val_gender_output_loss: 0.9547 - val_loss: 10968.7988 - val_race_output_loss: 1.9791 - learning_rate: 5.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 134.9779 - age_output_mae: 8.5593 - gender_output_loss: 0.6630 - loss: 134.9982 - race_output_loss: 1.3636\n",
            "Epoch 2: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - age_output_loss: 134.9696 - age_output_mae: 8.5590 - gender_output_loss: 0.6630 - loss: 134.9900 - race_output_loss: 1.3636 - val_age_output_loss: 1191.4254 - val_age_output_mae: 30.1870 - val_gender_output_loss: 0.7697 - val_loss: 1186.9934 - val_race_output_loss: 1.4239 - learning_rate: 5.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 101.3582 - age_output_mae: 7.3963 - gender_output_loss: 0.6566 - loss: 101.3783 - race_output_loss: 1.3552\n",
            "Epoch 3: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - age_output_loss: 101.3561 - age_output_mae: 7.3961 - gender_output_loss: 0.6566 - loss: 101.3761 - race_output_loss: 1.3551 - val_age_output_loss: 359.1693 - val_age_output_mae: 15.7448 - val_gender_output_loss: 0.6439 - val_loss: 357.5446 - val_race_output_loss: 1.3627 - learning_rate: 5.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - age_output_loss: 85.2466 - age_output_mae: 6.7445 - gender_output_loss: 0.6417 - loss: 85.2665 - race_output_loss: 1.3423\n",
            "Epoch 4: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - age_output_loss: 85.2516 - age_output_mae: 6.7449 - gender_output_loss: 0.6417 - loss: 85.2711 - race_output_loss: 1.3423 - val_age_output_loss: 164.0045 - val_age_output_mae: 10.1777 - val_gender_output_loss: 0.6760 - val_loss: 162.9532 - val_race_output_loss: 1.3643 - learning_rate: 5.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - age_output_loss: 73.2644 - age_output_mae: 6.2697 - gender_output_loss: 0.6449 - loss: 73.2843 - race_output_loss: 1.3500\n",
            "Epoch 5: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - age_output_loss: 73.2678 - age_output_mae: 6.2698 - gender_output_loss: 0.6449 - loss: 73.2877 - race_output_loss: 1.3500 - val_age_output_loss: 170.1568 - val_age_output_mae: 10.1962 - val_gender_output_loss: 0.6430 - val_loss: 168.6921 - val_race_output_loss: 1.3434 - learning_rate: 5.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - age_output_loss: 67.7139 - age_output_mae: 6.0375 - gender_output_loss: 0.6328 - loss: 67.7336 - race_output_loss: 1.3319\n",
            "Epoch 6: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - age_output_loss: 67.7172 - age_output_mae: 6.0376 - gender_output_loss: 0.6328 - loss: 67.7369 - race_output_loss: 1.3319 - val_age_output_loss: 187.1464 - val_age_output_mae: 10.8103 - val_gender_output_loss: 0.6413 - val_loss: 185.7905 - val_race_output_loss: 1.3410 - learning_rate: 5.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - age_output_loss: 59.9781 - age_output_mae: 5.6863 - gender_output_loss: 0.6352 - loss: 59.9978 - race_output_loss: 1.3363\n",
            "Epoch 7: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - age_output_loss: 59.9923 - age_output_mae: 5.6868 - gender_output_loss: 0.6352 - loss: 60.0120 - race_output_loss: 1.3363 - val_age_output_loss: 132.7886 - val_age_output_mae: 8.7833 - val_gender_output_loss: 0.6501 - val_loss: 132.7592 - val_race_output_loss: 1.3886 - learning_rate: 5.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - age_output_loss: 55.3708 - age_output_mae: 5.4445 - gender_output_loss: 0.6283 - loss: 55.3906 - race_output_loss: 1.3417\n",
            "Epoch 8: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - age_output_loss: 55.3921 - age_output_mae: 5.4456 - gender_output_loss: 0.6283 - loss: 55.4116 - race_output_loss: 1.3416 - val_age_output_loss: 196.2763 - val_age_output_mae: 11.0116 - val_gender_output_loss: 0.6434 - val_loss: 196.0221 - val_race_output_loss: 1.4475 - learning_rate: 5.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - age_output_loss: 54.1687 - age_output_mae: 5.3764 - gender_output_loss: 0.6337 - loss: 54.1885 - race_output_loss: 1.3449\n",
            "Epoch 9: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - age_output_loss: 54.1725 - age_output_mae: 5.3766 - gender_output_loss: 0.6337 - loss: 54.1924 - race_output_loss: 1.3449 - val_age_output_loss: 136.3591 - val_age_output_mae: 8.7368 - val_gender_output_loss: 0.6337 - val_loss: 136.5617 - val_race_output_loss: 1.4050 - learning_rate: 5.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - age_output_loss: 55.1483 - age_output_mae: 5.4121 - gender_output_loss: 0.6231 - loss: 55.1680 - race_output_loss: 1.3467\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 129.38237\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - age_output_loss: 55.1503 - age_output_mae: 5.4122 - gender_output_loss: 0.6231 - loss: 55.1700 - race_output_loss: 1.3467 - val_age_output_loss: 144.3431 - val_age_output_mae: 8.3428 - val_gender_output_loss: 0.6490 - val_loss: 144.9785 - val_race_output_loss: 1.4405 - learning_rate: 5.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 40.6168 - age_output_mae: 4.6921 - gender_output_loss: 0.6149 - loss: 40.6363 - race_output_loss: 1.3360\n",
            "Epoch 11: val_loss improved from 129.38237 to 93.32256, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - age_output_loss: 40.6127 - age_output_mae: 4.6919 - gender_output_loss: 0.6150 - loss: 40.6322 - race_output_loss: 1.3360 - val_age_output_loss: 94.5445 - val_age_output_mae: 6.7611 - val_gender_output_loss: 0.6166 - val_loss: 93.3226 - val_race_output_loss: 1.3444 - learning_rate: 2.5000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 32.7210 - age_output_mae: 4.2105 - gender_output_loss: 0.6273 - loss: 32.7407 - race_output_loss: 1.3399\n",
            "Epoch 12: val_loss improved from 93.32256 to 86.66000, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - age_output_loss: 32.7259 - age_output_mae: 4.2109 - gender_output_loss: 0.6273 - loss: 32.7456 - race_output_loss: 1.3398 - val_age_output_loss: 86.6415 - val_age_output_mae: 6.4239 - val_gender_output_loss: 0.6146 - val_loss: 86.6600 - val_race_output_loss: 1.3373 - learning_rate: 2.5000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 31.6679 - age_output_mae: 4.1441 - gender_output_loss: 0.6251 - loss: 31.6875 - race_output_loss: 1.3386\n",
            "Epoch 13: val_loss improved from 86.66000 to 82.82124, saving model to best_model_e3ttcqgq.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - age_output_loss: 31.6687 - age_output_mae: 4.1442 - gender_output_loss: 0.6251 - loss: 31.6884 - race_output_loss: 1.3386 - val_age_output_loss: 82.9876 - val_age_output_mae: 6.3930 - val_gender_output_loss: 0.6189 - val_loss: 82.8212 - val_race_output_loss: 1.3569 - learning_rate: 2.5000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 31.3395 - age_output_mae: 4.1309 - gender_output_loss: 0.6337 - loss: 31.3592 - race_output_loss: 1.3442\n",
            "Epoch 14: val_loss did not improve from 82.82124\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - age_output_loss: 31.3408 - age_output_mae: 4.1309 - gender_output_loss: 0.6337 - loss: 31.3605 - race_output_loss: 1.3442 - val_age_output_loss: 89.1690 - val_age_output_mae: 6.6357 - val_gender_output_loss: 0.6168 - val_loss: 88.8473 - val_race_output_loss: 1.3676 - learning_rate: 2.5000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - age_output_loss: 31.2512 - age_output_mae: 4.0977 - gender_output_loss: 0.6304 - loss: 31.2711 - race_output_loss: 1.3598\n",
            "Epoch 15: val_loss did not improve from 82.82124\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - age_output_loss: 31.2519 - age_output_mae: 4.0978 - gender_output_loss: 0.6304 - loss: 31.2717 - race_output_loss: 1.3598 - val_age_output_loss: 97.3125 - val_age_output_mae: 7.1144 - val_gender_output_loss: 0.6078 - val_loss: 97.4334 - val_race_output_loss: 1.3478 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 13.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bias_gap</td><td>â–</td></tr><tr><td>mean_group_mae</td><td>â–</td></tr><tr><td>overall_mae</td><td>â–</td></tr><tr><td>worst_group_mae</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bias_gap</td><td>2.36751</td></tr><tr><td>mean_group_mae</td><td>6.07135</td></tr><tr><td>overall_mae</td><td>6.39304</td></tr><tr><td>worst_group_mae</td><td>7.192</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resilient-sweep-5</strong> at: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/e3ttcqgq' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/e3ttcqgq</a><br> View project at: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260219_203026-e3ttcqgq/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3az66pjw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_loss_weight: 0.02\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.35\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stop_patience: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_unfreeze: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treduce_lr_factor: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treduce_lr_patience: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260219_204007-3az66pjw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/3az66pjw' target=\"_blank\">fresh-sweep-6</a></strong> to <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/3az66pjw' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/3az66pjw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training with config:\n",
            "{'adv_loss_weight': 0.02, 'batch_size': 32, 'dropout_rate': 0.35, 'early_stop_patience': 5, 'learning_rate': 0.0001, 'n_unfreeze': 25, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 3, 'weight_decay': 0.0001}\n",
            "============================================================\n",
            "Epoch 1/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 582.9896 - mae: 18.1330\n",
            "Epoch 1: val_loss improved from inf to 211.12244, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 32ms/step - loss: 582.6361 - mae: 18.1267 - val_loss: 211.1224 - val_mae: 11.0489 - learning_rate: 1.0000e-04\n",
            "Epoch 2/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 214.5625 - mae: 11.2740\n",
            "Epoch 2: val_loss improved from 211.12244 to 184.18570, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 214.5126 - mae: 11.2731 - val_loss: 184.1857 - val_mae: 10.3573 - learning_rate: 1.0000e-04\n",
            "Epoch 3/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 190.7874 - mae: 10.6305\n",
            "Epoch 3: val_loss improved from 184.18570 to 170.35141, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 190.7765 - mae: 10.6301 - val_loss: 170.3514 - val_mae: 9.9742 - learning_rate: 1.0000e-04\n",
            "Epoch 4/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 180.5170 - mae: 10.2810\n",
            "Epoch 4: val_loss improved from 170.35141 to 161.97502, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 180.4908 - mae: 10.2804 - val_loss: 161.9750 - val_mae: 9.6613 - learning_rate: 1.0000e-04\n",
            "Epoch 5/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 167.4396 - mae: 9.9082\n",
            "Epoch 5: val_loss improved from 161.97502 to 155.98730, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 167.4449 - mae: 9.9083 - val_loss: 155.9873 - val_mae: 9.3956 - learning_rate: 1.0000e-04\n",
            "Epoch 6/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 164.2589 - mae: 9.7633\n",
            "Epoch 6: val_loss improved from 155.98730 to 151.34119, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 164.2566 - mae: 9.7632 - val_loss: 151.3412 - val_mae: 9.2778 - learning_rate: 1.0000e-04\n",
            "Epoch 7/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 158.7505 - mae: 9.5693\n",
            "Epoch 7: val_loss improved from 151.34119 to 147.52408, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 158.7372 - mae: 9.5689 - val_loss: 147.5241 - val_mae: 9.0937 - learning_rate: 1.0000e-04\n",
            "Epoch 8/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 152.7358 - mae: 9.4159\n",
            "Epoch 8: val_loss improved from 147.52408 to 145.45853, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 152.7390 - mae: 9.4159 - val_loss: 145.4585 - val_mae: 8.9677 - learning_rate: 1.0000e-04\n",
            "Epoch 9/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 152.3644 - mae: 9.3188\n",
            "Epoch 9: val_loss improved from 145.45853 to 143.07230, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 152.3592 - mae: 9.3186 - val_loss: 143.0723 - val_mae: 8.8650 - learning_rate: 1.0000e-04\n",
            "Epoch 10/35\n",
            "\u001b[1m588/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 149.1084 - mae: 9.2442\n",
            "Epoch 10: val_loss improved from 143.07230 to 139.68791, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 149.1042 - mae: 9.2438 - val_loss: 139.6879 - val_mae: 8.8416 - learning_rate: 1.0000e-04\n",
            "Epoch 11/35\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 146.0570 - mae: 9.0786\n",
            "Epoch 11: val_loss improved from 139.68791 to 137.84579, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 146.0484 - mae: 9.0787 - val_loss: 137.8458 - val_mae: 8.7050 - learning_rate: 1.0000e-04\n",
            "Epoch 12/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 142.7866 - mae: 8.9691\n",
            "Epoch 12: val_loss improved from 137.84579 to 136.75618, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 142.7913 - mae: 8.9694 - val_loss: 136.7562 - val_mae: 8.6432 - learning_rate: 1.0000e-04\n",
            "Epoch 13/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 144.2474 - mae: 9.0297\n",
            "Epoch 13: val_loss improved from 136.75618 to 134.83415, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 144.2336 - mae: 9.0293 - val_loss: 134.8342 - val_mae: 8.6306 - learning_rate: 1.0000e-04\n",
            "Epoch 14/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 140.7133 - mae: 8.9476\n",
            "Epoch 14: val_loss improved from 134.83415 to 134.08069, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 140.7101 - mae: 8.9476 - val_loss: 134.0807 - val_mae: 8.6394 - learning_rate: 1.0000e-04\n",
            "Epoch 15/35\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 140.5598 - mae: 8.9174\n",
            "Epoch 15: val_loss improved from 134.08069 to 132.68260, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 140.5365 - mae: 8.9167 - val_loss: 132.6826 - val_mae: 8.5148 - learning_rate: 1.0000e-04\n",
            "Epoch 16/35\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 139.6299 - mae: 8.8966\n",
            "Epoch 16: val_loss improved from 132.68260 to 131.73944, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 139.6163 - mae: 8.8960 - val_loss: 131.7394 - val_mae: 8.5131 - learning_rate: 1.0000e-04\n",
            "Epoch 17/35\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 135.6541 - mae: 8.7558\n",
            "Epoch 17: val_loss improved from 131.73944 to 130.98676, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 135.6564 - mae: 8.7558 - val_loss: 130.9868 - val_mae: 8.4659 - learning_rate: 1.0000e-04\n",
            "Epoch 18/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 137.6355 - mae: 8.7484\n",
            "Epoch 18: val_loss improved from 130.98676 to 130.33189, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 137.6246 - mae: 8.7483 - val_loss: 130.3319 - val_mae: 8.4111 - learning_rate: 1.0000e-04\n",
            "Epoch 19/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 131.7397 - mae: 8.6123\n",
            "Epoch 19: val_loss improved from 130.33189 to 129.53531, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 131.7420 - mae: 8.6124 - val_loss: 129.5353 - val_mae: 8.4481 - learning_rate: 1.0000e-04\n",
            "Epoch 20/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 131.7942 - mae: 8.6667\n",
            "Epoch 20: val_loss improved from 129.53531 to 128.94511, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 131.7910 - mae: 8.6665 - val_loss: 128.9451 - val_mae: 8.3543 - learning_rate: 1.0000e-04\n",
            "Epoch 21/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 129.3431 - mae: 8.5572\n",
            "Epoch 21: val_loss improved from 128.94511 to 128.24643, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 129.3403 - mae: 8.5570 - val_loss: 128.2464 - val_mae: 8.3516 - learning_rate: 1.0000e-04\n",
            "Epoch 22/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 130.5567 - mae: 8.5807\n",
            "Epoch 22: val_loss did not improve from 128.24643\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 130.5526 - mae: 8.5806 - val_loss: 128.7464 - val_mae: 8.3420 - learning_rate: 1.0000e-04\n",
            "Epoch 23/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 131.4277 - mae: 8.6042\n",
            "Epoch 23: val_loss improved from 128.24643 to 127.93475, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 131.4141 - mae: 8.6038 - val_loss: 127.9347 - val_mae: 8.3867 - learning_rate: 1.0000e-04\n",
            "Epoch 24/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 129.7841 - mae: 8.5777\n",
            "Epoch 24: val_loss did not improve from 127.93475\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 129.7746 - mae: 8.5774 - val_loss: 128.5083 - val_mae: 8.3309 - learning_rate: 1.0000e-04\n",
            "Epoch 25/35\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 126.3706 - mae: 8.4173\n",
            "Epoch 25: val_loss improved from 127.93475 to 126.83179, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 126.3706 - mae: 8.4173 - val_loss: 126.8318 - val_mae: 8.3317 - learning_rate: 1.0000e-04\n",
            "Epoch 26/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 125.6439 - mae: 8.4224\n",
            "Epoch 26: val_loss did not improve from 126.83179\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 125.6450 - mae: 8.4225 - val_loss: 127.1172 - val_mae: 8.2818 - learning_rate: 1.0000e-04\n",
            "Epoch 27/35\n",
            "\u001b[1m587/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 122.6192 - mae: 8.3294\n",
            "Epoch 27: val_loss improved from 126.83179 to 126.19358, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 122.6383 - mae: 8.3299 - val_loss: 126.1936 - val_mae: 8.3433 - learning_rate: 1.0000e-04\n",
            "Epoch 28/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 124.4066 - mae: 8.3854\n",
            "Epoch 28: val_loss improved from 126.19358 to 126.01567, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 124.4058 - mae: 8.3854 - val_loss: 126.0157 - val_mae: 8.2825 - learning_rate: 1.0000e-04\n",
            "Epoch 29/35\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 122.2127 - mae: 8.3357\n",
            "Epoch 29: val_loss improved from 126.01567 to 125.56582, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 122.2136 - mae: 8.3357 - val_loss: 125.5658 - val_mae: 8.2982 - learning_rate: 1.0000e-04\n",
            "Epoch 30/35\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 116.8069 - mae: 8.1024\n",
            "Epoch 30: val_loss did not improve from 125.56582\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 116.8398 - mae: 8.1035 - val_loss: 126.4618 - val_mae: 8.2613 - learning_rate: 1.0000e-04\n",
            "Epoch 31/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 122.2167 - mae: 8.2817\n",
            "Epoch 31: val_loss did not improve from 125.56582\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 122.2149 - mae: 8.2818 - val_loss: 127.1449 - val_mae: 8.4349 - learning_rate: 1.0000e-04\n",
            "Epoch 32/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 119.8143 - mae: 8.2867\n",
            "Epoch 32: val_loss improved from 125.56582 to 125.17028, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 119.8143 - mae: 8.2866 - val_loss: 125.1703 - val_mae: 8.2903 - learning_rate: 1.0000e-04\n",
            "Epoch 33/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 118.5941 - mae: 8.2276\n",
            "Epoch 33: val_loss improved from 125.17028 to 125.15337, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 118.5900 - mae: 8.2275 - val_loss: 125.1534 - val_mae: 8.2544 - learning_rate: 1.0000e-04\n",
            "Epoch 34/35\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 116.7941 - mae: 8.1588\n",
            "Epoch 34: val_loss did not improve from 125.15337\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 116.7970 - mae: 8.1589 - val_loss: 125.2918 - val_mae: 8.2448 - learning_rate: 1.0000e-04\n",
            "Epoch 35/35\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 116.9949 - mae: 8.1279\n",
            "Epoch 35: val_loss improved from 125.15337 to 124.84612, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 116.9996 - mae: 8.1282 - val_loss: 124.8461 - val_mae: 8.2483 - learning_rate: 1.0000e-04\n",
            "Epoch 1/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - gender_output_loss: 9.3208 - loss: 45.4935 - race_output_loss: 36.1727\n",
            "Epoch 2/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - gender_output_loss: 8.0986 - loss: 32.8235 - race_output_loss: 24.7248\n",
            "Epoch 3/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - gender_output_loss: 7.2587 - loss: 20.4459 - race_output_loss: 13.1872\n",
            "Epoch 4/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - gender_output_loss: 6.3037 - loss: 22.3595 - race_output_loss: 16.0557\n",
            "Epoch 5/5\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - gender_output_loss: 3.2515 - loss: 19.2950 - race_output_loss: 16.0435\n",
            "Epoch 1/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - age_output_loss: 1596.2993 - age_output_mae: 29.5548 - gender_output_loss: 1.0726 - loss: 1596.4788 - race_output_loss: 7.8888\n",
            "Epoch 1: val_loss did not improve from 124.84612\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 44ms/step - age_output_loss: 1594.8474 - age_output_mae: 29.5374 - gender_output_loss: 1.0724 - loss: 1595.0273 - race_output_loss: 7.8831 - val_age_output_loss: 298.7978 - val_age_output_mae: 13.5830 - val_gender_output_loss: 1.5720 - val_loss: 298.8279 - val_race_output_loss: 5.6250 - learning_rate: 5.0000e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 188.0523 - age_output_mae: 10.5028 - gender_output_loss: 0.7344 - loss: 188.1078 - race_output_loss: 2.0416\n",
            "Epoch 2: val_loss did not improve from 124.84612\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - age_output_loss: 187.9996 - age_output_mae: 10.5012 - gender_output_loss: 0.7343 - loss: 188.0551 - race_output_loss: 2.0408 - val_age_output_loss: 160.7000 - val_age_output_mae: 9.5004 - val_gender_output_loss: 0.8193 - val_loss: 159.9861 - val_race_output_loss: 3.0316 - learning_rate: 5.0000e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - age_output_loss: 141.3891 - age_output_mae: 9.0967 - gender_output_loss: 0.6890 - loss: 141.4356 - race_output_loss: 1.6372\n",
            "Epoch 3: val_loss did not improve from 124.84612\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - age_output_loss: 141.3812 - age_output_mae: 9.0962 - gender_output_loss: 0.6890 - loss: 141.4278 - race_output_loss: 1.6370 - val_age_output_loss: 148.6185 - val_age_output_mae: 9.0142 - val_gender_output_loss: 0.6778 - val_loss: 147.8475 - val_race_output_loss: 1.9509 - learning_rate: 5.0000e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - age_output_loss: 120.3268 - age_output_mae: 8.3573 - gender_output_loss: 0.6681 - loss: 120.3714 - race_output_loss: 1.5637\n",
            "Epoch 4: val_loss improved from 124.84612 to 118.53180, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - age_output_loss: 120.3150 - age_output_mae: 8.3568 - gender_output_loss: 0.6681 - loss: 120.3595 - race_output_loss: 1.5635 - val_age_output_loss: 121.1122 - val_age_output_mae: 8.0485 - val_gender_output_loss: 0.6577 - val_loss: 118.5318 - val_race_output_loss: 1.5914 - learning_rate: 5.0000e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 106.0765 - age_output_mae: 7.8468 - gender_output_loss: 0.6677 - loss: 106.1200 - race_output_loss: 1.5023\n",
            "Epoch 5: val_loss improved from 118.53180 to 117.14494, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - age_output_loss: 106.0754 - age_output_mae: 7.8468 - gender_output_loss: 0.6677 - loss: 106.1186 - race_output_loss: 1.5023 - val_age_output_loss: 119.4471 - val_age_output_mae: 7.9995 - val_gender_output_loss: 0.6529 - val_loss: 117.1449 - val_race_output_loss: 1.4937 - learning_rate: 5.0000e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 92.4316 - age_output_mae: 7.3193 - gender_output_loss: 0.6645 - loss: 92.4743 - race_output_loss: 1.4716\n",
            "Epoch 6: val_loss improved from 117.14494 to 113.77619, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - age_output_loss: 92.4329 - age_output_mae: 7.3194 - gender_output_loss: 0.6645 - loss: 92.4756 - race_output_loss: 1.4716 - val_age_output_loss: 115.5473 - val_age_output_mae: 7.8633 - val_gender_output_loss: 0.6533 - val_loss: 113.7762 - val_race_output_loss: 1.4669 - learning_rate: 5.0000e-05\n",
            "Epoch 7/15\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - age_output_loss: 80.3468 - age_output_mae: 6.8786 - gender_output_loss: 0.6610 - loss: 80.3890 - race_output_loss: 1.4469\n",
            "Epoch 7: val_loss did not improve from 113.77619\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - age_output_loss: 80.3499 - age_output_mae: 6.8787 - gender_output_loss: 0.6610 - loss: 80.3922 - race_output_loss: 1.4469 - val_age_output_loss: 117.5807 - val_age_output_mae: 7.8649 - val_gender_output_loss: 0.6534 - val_loss: 115.9382 - val_race_output_loss: 1.4452 - learning_rate: 5.0000e-05\n",
            "Epoch 8/15\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - age_output_loss: 72.4160 - age_output_mae: 6.4837 - gender_output_loss: 0.6691 - loss: 72.4580 - race_output_loss: 1.4278\n",
            "Epoch 8: val_loss did not improve from 113.77619\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - age_output_loss: 72.4174 - age_output_mae: 6.4839 - gender_output_loss: 0.6691 - loss: 72.4594 - race_output_loss: 1.4277 - val_age_output_loss: 120.7378 - val_age_output_mae: 7.9876 - val_gender_output_loss: 0.6567 - val_loss: 119.9230 - val_race_output_loss: 1.4347 - learning_rate: 5.0000e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 64.7824 - age_output_mae: 6.1520 - gender_output_loss: 0.6617 - loss: 64.8240 - race_output_loss: 1.4170\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 113.77619\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - age_output_loss: 64.7842 - age_output_mae: 6.1521 - gender_output_loss: 0.6617 - loss: 64.8257 - race_output_loss: 1.4170 - val_age_output_loss: 123.0136 - val_age_output_mae: 8.0211 - val_gender_output_loss: 0.6535 - val_loss: 121.0050 - val_race_output_loss: 1.4131 - learning_rate: 5.0000e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - age_output_loss: 56.0036 - age_output_mae: 5.7320 - gender_output_loss: 0.6582 - loss: 56.0448 - race_output_loss: 1.4017\n",
            "Epoch 10: val_loss improved from 113.77619 to 105.16216, saving model to best_model_3az66pjw.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - age_output_loss: 56.0059 - age_output_mae: 5.7321 - gender_output_loss: 0.6582 - loss: 56.0471 - race_output_loss: 1.4017 - val_age_output_loss: 106.2789 - val_age_output_mae: 7.4283 - val_gender_output_loss: 0.6516 - val_loss: 105.1622 - val_race_output_loss: 1.4041 - learning_rate: 2.5000e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m592/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - age_output_loss: 53.0753 - age_output_mae: 5.5571 - gender_output_loss: 0.6619 - loss: 53.1166 - race_output_loss: 1.4026\n",
            "Epoch 11: val_loss did not improve from 105.16216\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - age_output_loss: 53.0732 - age_output_mae: 5.5570 - gender_output_loss: 0.6619 - loss: 53.1144 - race_output_loss: 1.4026 - val_age_output_loss: 110.0543 - val_age_output_mae: 7.5230 - val_gender_output_loss: 0.6604 - val_loss: 108.1015 - val_race_output_loss: 1.3991 - learning_rate: 2.5000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - age_output_loss: 49.5953 - age_output_mae: 5.4009 - gender_output_loss: 0.6638 - loss: 49.6365 - race_output_loss: 1.3934\n",
            "Epoch 12: val_loss did not improve from 105.16216\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - age_output_loss: 49.5977 - age_output_mae: 5.4009 - gender_output_loss: 0.6638 - loss: 49.6388 - race_output_loss: 1.3934 - val_age_output_loss: 110.6000 - val_age_output_mae: 7.5497 - val_gender_output_loss: 0.6576 - val_loss: 109.2067 - val_race_output_loss: 1.3958 - learning_rate: 2.5000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m590/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - age_output_loss: 47.7038 - age_output_mae: 5.2700 - gender_output_loss: 0.6629 - loss: 47.7449 - race_output_loss: 1.3905\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 105.16216\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - age_output_loss: 47.7034 - age_output_mae: 5.2699 - gender_output_loss: 0.6629 - loss: 47.7445 - race_output_loss: 1.3905 - val_age_output_loss: 109.3914 - val_age_output_mae: 7.5726 - val_gender_output_loss: 0.6549 - val_loss: 108.5360 - val_race_output_loss: 1.3931 - learning_rate: 2.5000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m591/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - age_output_loss: 45.1911 - age_output_mae: 5.1232 - gender_output_loss: 0.6657 - loss: 45.2324 - race_output_loss: 1.4006\n",
            "Epoch 14: val_loss did not improve from 105.16216\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - age_output_loss: 45.1882 - age_output_mae: 5.1230 - gender_output_loss: 0.6657 - loss: 45.2294 - race_output_loss: 1.4006 - val_age_output_loss: 110.8895 - val_age_output_mae: 7.6192 - val_gender_output_loss: 0.6551 - val_loss: 109.6061 - val_race_output_loss: 1.3912 - learning_rate: 1.2500e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m589/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - age_output_loss: 43.0644 - age_output_mae: 5.0066 - gender_output_loss: 0.6637 - loss: 43.1054 - race_output_loss: 1.3880\n",
            "Epoch 15: val_loss did not improve from 105.16216\n",
            "\u001b[1m593/593\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - age_output_loss: 43.0565 - age_output_mae: 5.0061 - gender_output_loss: 0.6637 - loss: 43.0975 - race_output_loss: 1.3880 - val_age_output_loss: 107.1426 - val_age_output_mae: 7.4838 - val_gender_output_loss: 0.6547 - val_loss: 105.8393 - val_race_output_loss: 1.3888 - learning_rate: 1.2500e-05\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bias_gap</td><td>â–</td></tr><tr><td>mean_group_mae</td><td>â–</td></tr><tr><td>overall_mae</td><td>â–</td></tr><tr><td>worst_group_mae</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bias_gap</td><td>2.54287</td></tr><tr><td>mean_group_mae</td><td>7.10984</td></tr><tr><td>overall_mae</td><td>7.42827</td></tr><tr><td>worst_group_mae</td><td>8.13728</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fresh-sweep-6</strong> at: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/3az66pjw' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/3az66pjw</a><br> View project at: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260219_204007-3az66pjw/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2335thn5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_loss_weight: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stop_patience: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_unfreeze: 35\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treduce_lr_factor: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treduce_lr_patience: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260219_204919-2335thn5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/2335thn5' target=\"_blank\">wise-sweep-6</a></strong> to <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/2335thn5' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/2335thn5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training with config:\n",
            "{'adv_loss_weight': 0.005, 'batch_size': 16, 'dropout_rate': 0.3, 'early_stop_patience': 5, 'learning_rate': 0.001, 'n_unfreeze': 35, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 3, 'weight_decay': 0.0001}\n",
            "============================================================\n",
            "Epoch 1/35\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 251.6448 - mae: 11.9625\n",
            "Epoch 1: val_loss improved from inf to 144.94975, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - loss: 251.5939 - mae: 11.9612 - val_loss: 144.9498 - val_mae: 9.0281 - learning_rate: 0.0010\n",
            "Epoch 2/35\n",
            "\u001b[1m1179/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 153.7699 - mae: 9.3598\n",
            "Epoch 2: val_loss improved from 144.94975 to 141.01456, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 153.7731 - mae: 9.3598 - val_loss: 141.0146 - val_mae: 8.8173 - learning_rate: 0.0010\n",
            "Epoch 3/35\n",
            "\u001b[1m1181/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 147.6999 - mae: 9.1900\n",
            "Epoch 3: val_loss improved from 141.01456 to 137.16811, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 147.6946 - mae: 9.1896 - val_loss: 137.1681 - val_mae: 8.6454 - learning_rate: 0.0010\n",
            "Epoch 4/35\n",
            "\u001b[1m1184/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 141.5472 - mae: 8.9051\n",
            "Epoch 4: val_loss improved from 137.16811 to 135.98004, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 141.5449 - mae: 8.9050 - val_loss: 135.9800 - val_mae: 8.5818 - learning_rate: 0.0010\n",
            "Epoch 5/35\n",
            "\u001b[1m1180/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 135.9685 - mae: 8.7865\n",
            "Epoch 5: val_loss improved from 135.98004 to 134.39233, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 135.9793 - mae: 8.7867 - val_loss: 134.3923 - val_mae: 8.5538 - learning_rate: 0.0010\n",
            "Epoch 6/35\n",
            "\u001b[1m1180/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 132.9749 - mae: 8.6671\n",
            "Epoch 6: val_loss improved from 134.39233 to 133.67464, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 132.9757 - mae: 8.6671 - val_loss: 133.6746 - val_mae: 8.7167 - learning_rate: 0.0010\n",
            "Epoch 7/35\n",
            "\u001b[1m1179/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 128.0216 - mae: 8.5246\n",
            "Epoch 7: val_loss improved from 133.67464 to 130.49577, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 128.0432 - mae: 8.5250 - val_loss: 130.4958 - val_mae: 8.4520 - learning_rate: 0.0010\n",
            "Epoch 8/35\n",
            "\u001b[1m1182/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 127.0943 - mae: 8.4331\n",
            "Epoch 8: val_loss did not improve from 130.49577\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 127.0990 - mae: 8.4334 - val_loss: 134.1568 - val_mae: 8.6351 - learning_rate: 0.0010\n",
            "Epoch 9/35\n",
            "\u001b[1m1180/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 124.0074 - mae: 8.3772\n",
            "Epoch 9: val_loss did not improve from 130.49577\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 124.0121 - mae: 8.3773 - val_loss: 136.7835 - val_mae: 8.4995 - learning_rate: 0.0010\n",
            "Epoch 10/35\n",
            "\u001b[1m1185/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 121.0048 - mae: 8.2548\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 130.49577\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 121.0055 - mae: 8.2548 - val_loss: 131.1697 - val_mae: 8.3818 - learning_rate: 0.0010\n",
            "Epoch 11/35\n",
            "\u001b[1m1185/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 117.2446 - mae: 8.0666\n",
            "Epoch 11: val_loss improved from 130.49577 to 128.30060, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 117.2403 - mae: 8.0665 - val_loss: 128.3006 - val_mae: 8.3510 - learning_rate: 5.0000e-04\n",
            "Epoch 12/35\n",
            "\u001b[1m1183/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 110.0167 - mae: 7.8826\n",
            "Epoch 12: val_loss did not improve from 128.30060\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 110.0271 - mae: 7.8829 - val_loss: 128.5113 - val_mae: 8.3500 - learning_rate: 5.0000e-04\n",
            "Epoch 13/35\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 109.3950 - mae: 7.8373\n",
            "Epoch 13: val_loss improved from 128.30060 to 128.04774, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 109.3965 - mae: 7.8374 - val_loss: 128.0477 - val_mae: 8.3281 - learning_rate: 5.0000e-04\n",
            "Epoch 14/35\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 108.5292 - mae: 7.8255\n",
            "Epoch 14: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 108.5294 - mae: 7.8255 - val_loss: 132.0511 - val_mae: 8.5541 - learning_rate: 5.0000e-04\n",
            "Epoch 15/35\n",
            "\u001b[1m1183/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 107.1674 - mae: 7.7913\n",
            "Epoch 15: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 107.1695 - mae: 7.7913 - val_loss: 128.9802 - val_mae: 8.3312 - learning_rate: 5.0000e-04\n",
            "Epoch 16/35\n",
            "\u001b[1m1185/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 107.2594 - mae: 7.7764\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 107.2596 - mae: 7.7764 - val_loss: 130.5317 - val_mae: 8.3526 - learning_rate: 5.0000e-04\n",
            "Epoch 17/35\n",
            "\u001b[1m1182/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 101.0998 - mae: 7.5564\n",
            "Epoch 17: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 101.1033 - mae: 7.5566 - val_loss: 129.3033 - val_mae: 8.4408 - learning_rate: 2.5000e-04\n",
            "Epoch 18/35\n",
            "\u001b[1m1179/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 100.7698 - mae: 7.5457\n",
            "Epoch 18: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 100.7747 - mae: 7.5458 - val_loss: 128.4114 - val_mae: 8.3367 - learning_rate: 2.5000e-04\n",
            "Epoch 19/35\n",
            "\u001b[1m1182/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 101.2688 - mae: 7.5403\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 101.2697 - mae: 7.5404 - val_loss: 128.8640 - val_mae: 8.3301 - learning_rate: 2.5000e-04\n",
            "Epoch 20/35\n",
            "\u001b[1m1185/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 98.5478 - mae: 7.4484\n",
            "Epoch 20: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 98.5472 - mae: 7.4484 - val_loss: 129.0148 - val_mae: 8.3230 - learning_rate: 1.2500e-04\n",
            "Epoch 21/35\n",
            "\u001b[1m1185/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 99.6533 - mae: 7.4417\n",
            "Epoch 21: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 99.6511 - mae: 7.4417 - val_loss: 128.9077 - val_mae: 8.4034 - learning_rate: 1.2500e-04\n",
            "Epoch 22/35\n",
            "\u001b[1m1181/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 96.1544 - mae: 7.3829\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 22: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 96.1552 - mae: 7.3829 - val_loss: 128.8304 - val_mae: 8.3651 - learning_rate: 1.2500e-04\n",
            "Epoch 23/35\n",
            "\u001b[1m1183/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 94.1254 - mae: 7.3228\n",
            "Epoch 23: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 94.1333 - mae: 7.3231 - val_loss: 128.5686 - val_mae: 8.3108 - learning_rate: 6.2500e-05\n",
            "Epoch 24/35\n",
            "\u001b[1m1185/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 95.7335 - mae: 7.3244\n",
            "Epoch 24: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 95.7351 - mae: 7.3245 - val_loss: 128.7890 - val_mae: 8.3186 - learning_rate: 6.2500e-05\n",
            "Epoch 25/35\n",
            "\u001b[1m1179/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 94.4163 - mae: 7.2837\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 94.4223 - mae: 7.2839 - val_loss: 128.9403 - val_mae: 8.3714 - learning_rate: 6.2500e-05\n",
            "Epoch 26/35\n",
            "\u001b[1m1182/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 94.5337 - mae: 7.3068\n",
            "Epoch 26: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 94.5401 - mae: 7.3070 - val_loss: 128.7765 - val_mae: 8.3349 - learning_rate: 3.1250e-05\n",
            "Epoch 27/35\n",
            "\u001b[1m1183/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 94.1461 - mae: 7.3005\n",
            "Epoch 27: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 94.1509 - mae: 7.3006 - val_loss: 128.9244 - val_mae: 8.3431 - learning_rate: 3.1250e-05\n",
            "Epoch 28/35\n",
            "\u001b[1m1183/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 94.4705 - mae: 7.2918\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 28: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 94.4707 - mae: 7.2918 - val_loss: 129.2885 - val_mae: 8.3717 - learning_rate: 3.1250e-05\n",
            "Epoch 29/35\n",
            "\u001b[1m1178/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 94.8332 - mae: 7.2769\n",
            "Epoch 29: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 94.8362 - mae: 7.2772 - val_loss: 128.8369 - val_mae: 8.3276 - learning_rate: 1.5625e-05\n",
            "Epoch 30/35\n",
            "\u001b[1m1184/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 92.9593 - mae: 7.2114\n",
            "Epoch 30: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 92.9630 - mae: 7.2116 - val_loss: 128.7683 - val_mae: 8.3179 - learning_rate: 1.5625e-05\n",
            "Epoch 31/35\n",
            "\u001b[1m1180/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 95.2965 - mae: 7.2964\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 31: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 95.2948 - mae: 7.2964 - val_loss: 128.8219 - val_mae: 8.3204 - learning_rate: 1.5625e-05\n",
            "Epoch 32/35\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 93.0566 - mae: 7.2495\n",
            "Epoch 32: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 93.0579 - mae: 7.2496 - val_loss: 128.8614 - val_mae: 8.3137 - learning_rate: 7.8125e-06\n",
            "Epoch 33/35\n",
            "\u001b[1m1185/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 95.4159 - mae: 7.3624\n",
            "Epoch 33: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 95.4154 - mae: 7.3624 - val_loss: 128.8380 - val_mae: 8.3250 - learning_rate: 7.8125e-06\n",
            "Epoch 34/35\n",
            "\u001b[1m1178/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 92.4479 - mae: 7.2431\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 34: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 92.4695 - mae: 7.2438 - val_loss: 128.8760 - val_mae: 8.3313 - learning_rate: 7.8125e-06\n",
            "Epoch 35/35\n",
            "\u001b[1m1182/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 92.9686 - mae: 7.2455\n",
            "Epoch 35: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 92.9735 - mae: 7.2457 - val_loss: 128.8624 - val_mae: 8.3319 - learning_rate: 3.9063e-06\n",
            "Epoch 1/5\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - gender_output_loss: 5.2635 - loss: 14.9312 - race_output_loss: 9.6676\n",
            "Epoch 2/5\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - gender_output_loss: 0.6484 - loss: 2.3679 - race_output_loss: 1.7195\n",
            "Epoch 3/5\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - gender_output_loss: 0.6657 - loss: 2.3515 - race_output_loss: 1.6858\n",
            "Epoch 4/5\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - gender_output_loss: 0.7829 - loss: 2.5939 - race_output_loss: 1.8110\n",
            "Epoch 5/5\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - gender_output_loss: 0.9029 - loss: 3.2001 - race_output_loss: 2.2972\n",
            "Epoch 1/15\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - age_output_loss: 23328.0527 - age_output_mae: 53.3328 - gender_output_loss: 0.7002 - loss: 23328.0664 - race_output_loss: 1.4892\n",
            "Epoch 1: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 27ms/step - age_output_loss: 23312.0195 - age_output_mae: 53.3051 - gender_output_loss: 0.7002 - loss: 23312.0332 - race_output_loss: 1.4892 - val_age_output_loss: 635.4811 - val_age_output_mae: 21.9587 - val_gender_output_loss: 0.6779 - val_loss: 635.5070 - val_race_output_loss: 1.3835 - learning_rate: 5.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m1181/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 187.5430 - age_output_mae: 10.2810 - gender_output_loss: 0.6684 - loss: 187.5533 - race_output_loss: 1.3828\n",
            "Epoch 2: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - age_output_loss: 187.4990 - age_output_mae: 10.2796 - gender_output_loss: 0.6684 - loss: 187.5061 - race_output_loss: 1.3828 - val_age_output_loss: 210.7341 - val_age_output_mae: 11.5098 - val_gender_output_loss: 0.6462 - val_loss: 208.9298 - val_race_output_loss: 1.3614 - learning_rate: 5.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m1185/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 147.5949 - age_output_mae: 9.0164 - gender_output_loss: 0.6582 - loss: 147.6050 - race_output_loss: 1.3733\n",
            "Epoch 3: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - age_output_loss: 147.5897 - age_output_mae: 9.0162 - gender_output_loss: 0.6581 - loss: 147.5999 - race_output_loss: 1.3733 - val_age_output_loss: 131.4185 - val_age_output_mae: 8.8014 - val_gender_output_loss: 0.6333 - val_loss: 131.3051 - val_race_output_loss: 1.3432 - learning_rate: 5.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m1184/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 118.2217 - age_output_mae: 8.0377 - gender_output_loss: 0.6464 - loss: 118.2318 - race_output_loss: 1.3515\n",
            "Epoch 4: val_loss did not improve from 128.04774\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - age_output_loss: 118.2285 - age_output_mae: 8.0378 - gender_output_loss: 0.6464 - loss: 118.2385 - race_output_loss: 1.3515 - val_age_output_loss: 174.5272 - val_age_output_mae: 9.9972 - val_gender_output_loss: 0.6331 - val_loss: 173.7487 - val_race_output_loss: 1.3498 - learning_rate: 5.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m1182/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 108.5344 - age_output_mae: 7.6399 - gender_output_loss: 0.6415 - loss: 108.5444 - race_output_loss: 1.3489\n",
            "Epoch 5: val_loss improved from 128.04774 to 103.47081, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - age_output_loss: 108.5303 - age_output_mae: 7.6397 - gender_output_loss: 0.6415 - loss: 108.5403 - race_output_loss: 1.3489 - val_age_output_loss: 103.6352 - val_age_output_mae: 7.3080 - val_gender_output_loss: 0.6216 - val_loss: 103.4708 - val_race_output_loss: 1.3670 - learning_rate: 5.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m1184/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 90.7193 - age_output_mae: 6.9621 - gender_output_loss: 0.6194 - loss: 90.7291 - race_output_loss: 1.3525\n",
            "Epoch 6: val_loss did not improve from 103.47081\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - age_output_loss: 90.7271 - age_output_mae: 6.9624 - gender_output_loss: 0.6194 - loss: 90.7369 - race_output_loss: 1.3525 - val_age_output_loss: 111.3119 - val_age_output_mae: 7.8462 - val_gender_output_loss: 0.6290 - val_loss: 111.2981 - val_race_output_loss: 1.4141 - learning_rate: 5.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m1182/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 87.3587 - age_output_mae: 6.8039 - gender_output_loss: 0.6246 - loss: 87.3687 - race_output_loss: 1.3675\n",
            "Epoch 7: val_loss did not improve from 103.47081\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - age_output_loss: 87.3689 - age_output_mae: 6.8043 - gender_output_loss: 0.6246 - loss: 87.3788 - race_output_loss: 1.3675 - val_age_output_loss: 301.7063 - val_age_output_mae: 12.8372 - val_gender_output_loss: 0.7168 - val_loss: 301.5338 - val_race_output_loss: 1.4261 - learning_rate: 5.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m1185/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 84.1239 - age_output_mae: 6.6976 - gender_output_loss: 0.6123 - loss: 84.1339 - race_output_loss: 1.3767\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 103.47081\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - age_output_loss: 84.1257 - age_output_mae: 6.6976 - gender_output_loss: 0.6123 - loss: 84.1357 - race_output_loss: 1.3767 - val_age_output_loss: 116.2937 - val_age_output_mae: 7.5103 - val_gender_output_loss: 0.6682 - val_loss: 116.3362 - val_race_output_loss: 1.4200 - learning_rate: 5.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m1184/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 66.2660 - age_output_mae: 5.9377 - gender_output_loss: 0.6088 - loss: 66.2759 - race_output_loss: 1.3583\n",
            "Epoch 9: val_loss improved from 103.47081 to 87.48560, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - age_output_loss: 66.2661 - age_output_mae: 5.9378 - gender_output_loss: 0.6087 - loss: 66.2760 - race_output_loss: 1.3583 - val_age_output_loss: 87.6984 - val_age_output_mae: 6.6251 - val_gender_output_loss: 0.5719 - val_loss: 87.4856 - val_race_output_loss: 1.3521 - learning_rate: 2.5000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 57.6992 - age_output_mae: 5.5937 - gender_output_loss: 0.6009 - loss: 57.7090 - race_output_loss: 1.3594\n",
            "Epoch 10: val_loss did not improve from 87.48560\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - age_output_loss: 57.7013 - age_output_mae: 5.5938 - gender_output_loss: 0.6009 - loss: 57.7112 - race_output_loss: 1.3594 - val_age_output_loss: 88.0781 - val_age_output_mae: 6.5813 - val_gender_output_loss: 0.6049 - val_loss: 87.8875 - val_race_output_loss: 1.3453 - learning_rate: 2.5000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m1181/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 52.5799 - age_output_mae: 5.3541 - gender_output_loss: 0.6112 - loss: 52.5898 - race_output_loss: 1.3624\n",
            "Epoch 11: val_loss did not improve from 87.48560\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - age_output_loss: 52.5902 - age_output_mae: 5.3545 - gender_output_loss: 0.6113 - loss: 52.6000 - race_output_loss: 1.3624 - val_age_output_loss: 93.5963 - val_age_output_mae: 6.8643 - val_gender_output_loss: 0.6339 - val_loss: 93.6438 - val_race_output_loss: 1.3732 - learning_rate: 2.5000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m1184/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 55.1359 - age_output_mae: 5.4468 - gender_output_loss: 0.6047 - loss: 55.1456 - race_output_loss: 1.3489\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 87.48560\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - age_output_loss: 55.1323 - age_output_mae: 5.4467 - gender_output_loss: 0.6047 - loss: 55.1421 - race_output_loss: 1.3489 - val_age_output_loss: 88.9993 - val_age_output_mae: 6.7856 - val_gender_output_loss: 0.6234 - val_loss: 88.7041 - val_race_output_loss: 1.3605 - learning_rate: 2.5000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m1184/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 40.8862 - age_output_mae: 4.7307 - gender_output_loss: 0.5900 - loss: 40.8958 - race_output_loss: 1.3467\n",
            "Epoch 13: val_loss improved from 87.48560 to 81.98135, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - age_output_loss: 40.8854 - age_output_mae: 4.7306 - gender_output_loss: 0.5899 - loss: 40.8951 - race_output_loss: 1.3467 - val_age_output_loss: 81.9842 - val_age_output_mae: 6.2868 - val_gender_output_loss: 0.6050 - val_loss: 81.9814 - val_race_output_loss: 1.3371 - learning_rate: 1.2500e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m1182/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 35.7787 - age_output_mae: 4.4321 - gender_output_loss: 0.5841 - loss: 35.7884 - race_output_loss: 1.3571\n",
            "Epoch 14: val_loss did not improve from 81.98135\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - age_output_loss: 35.7810 - age_output_mae: 4.4323 - gender_output_loss: 0.5841 - loss: 35.7907 - race_output_loss: 1.3570 - val_age_output_loss: 83.5879 - val_age_output_mae: 6.2127 - val_gender_output_loss: 0.5764 - val_loss: 83.6624 - val_race_output_loss: 1.3518 - learning_rate: 1.2500e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m1183/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - age_output_loss: 31.6683 - age_output_mae: 4.1891 - gender_output_loss: 0.5901 - loss: 31.6780 - race_output_loss: 1.3443\n",
            "Epoch 15: val_loss improved from 81.98135 to 80.12955, saving model to best_model_2335thn5.keras\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - age_output_loss: 31.6712 - age_output_mae: 4.1893 - gender_output_loss: 0.5901 - loss: 31.6808 - race_output_loss: 1.3443 - val_age_output_loss: 80.0869 - val_age_output_mae: 6.1730 - val_gender_output_loss: 0.6292 - val_loss: 80.1295 - val_race_output_loss: 1.3605 - learning_rate: 1.2500e-04\n",
            "Restoring model weights from the end of the best epoch: 15.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bias_gap</td><td>â–</td></tr><tr><td>mean_group_mae</td><td>â–</td></tr><tr><td>overall_mae</td><td>â–</td></tr><tr><td>worst_group_mae</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bias_gap</td><td>3.00781</td></tr><tr><td>mean_group_mae</td><td>5.78475</td></tr><tr><td>overall_mae</td><td>6.17297</td></tr><tr><td>worst_group_mae</td><td>7.05039</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wise-sweep-6</strong> at: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/2335thn5' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/2335thn5</a><br> View project at: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260219_204919-2335thn5/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dlibyokv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tadv_loss_weight: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.35\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stop_patience: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_unfreeze: 35\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treduce_lr_factor: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \treduce_lr_patience: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260219_210227-dlibyokv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/dlibyokv' target=\"_blank\">charmed-sweep-7</a></strong> to <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/sweeps/ewgkcoz3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/dlibyokv' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-gender-debiasing/runs/dlibyokv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training with config:\n",
            "{'adv_loss_weight': 0.005, 'batch_size': 16, 'dropout_rate': 0.35, 'early_stop_patience': 5, 'learning_rate': 0.001, 'n_unfreeze': 35, 'reduce_lr_factor': 0.5, 'reduce_lr_patience': 3, 'weight_decay': 0.0001}\n",
            "============================================================\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c45c844bb93055f8"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "c45c844bb93055f8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
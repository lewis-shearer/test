{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBCGNkiZzCPgAaHzykVm1O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lewis-shearer/test/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8ngauF3aEJA",
        "outputId": "7b668d1b-1995-42c8-e669-f21b6666f3fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'utkface-new' dataset.\n",
            "Path to dataset files: /kaggle/input/utkface-new\n",
            "Loading data...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import ttest_rel\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "try:\n",
        "    from wandb.keras import WandbCallback\n",
        "except ImportError:\n",
        "    from wandb.integration.keras import WandbCallback\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ðŸ§© KaggleHub dataset downloader\n",
        "import kagglehub\n",
        "\n",
        "# ============================\n",
        "# DOWNLOAD DATA\n",
        "# ============================\n",
        "# Download latest version of UTKFace from KaggleHub\n",
        "path = kagglehub.dataset_download(\"jangedoo/utkface-new\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "DATA_DIR = path  # use this as the data directory\n",
        "data_dir = os.path.join(path, \"UTKFace\")\n",
        "# ============================\n",
        "# 1. REPRODUCIBILITY\n",
        "# ============================\n",
        "def set_seed(seed):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "# ============================\n",
        "# 2. LOAD UTKFACE DATASET\n",
        "# ============================\n",
        "def parse_filename(fname):\n",
        "    parts = fname.split(\"_\")\n",
        "    return int(parts[0]), int(parts[1]), int(parts[2])\n",
        "\n",
        "def load_data(data_dir):\n",
        "    images, ages, genders, races = [], [], [], []\n",
        "    for fname in os.listdir(data_dir):\n",
        "        if fname.lower().endswith(\".jpg\"):\n",
        "            try:\n",
        "                age, gender, race = parse_filename(fname)\n",
        "                img_path = os.path.join(data_dir, fname)\n",
        "                img = Image.open(img_path).resize((96,96))\n",
        "                images.append(np.array(img)/255.0)\n",
        "                ages.append(age)\n",
        "                genders.append(gender)\n",
        "                races.append(race)\n",
        "            except:\n",
        "                continue\n",
        "    return (np.array(images, dtype=np.float32),\n",
        "            np.array(ages, dtype=np.float32),\n",
        "            np.array(genders),\n",
        "            np.array(races))\n",
        "\n",
        "print(\"Loading data...\")\n",
        "X, y_age, y_gender, y_race = load_data(data_dir)\n",
        "\n",
        "# ============================\n",
        "# 3. TRAIN/VAL/TEST SPLIT\n",
        "# ============================\n",
        "X_train, X_temp, y_age_train, y_age_temp, y_gender_train, y_gender_temp, y_race_train, y_race_temp = train_test_split(\n",
        "    X, y_age, y_gender, y_race,\n",
        "    test_size=0.3, stratify=y_race, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_age_val, y_age_test, y_gender_val, y_gender_test, y_race_val, y_race_test = train_test_split(\n",
        "    X_temp, y_age_temp, y_gender_temp, y_race_temp,\n",
        "    test_size=0.5, stratify=y_race_temp, random_state=42\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 4. HYPERPARAMETERS\n",
        "# ============================\n",
        "config = {\n",
        "    \"adv_loss_weight\": 0.01,\n",
        "    \"batch_size\": 32,\n",
        "    \"dropout_rate\": 0.25,\n",
        "    \"early_stop_patience\": 5,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"reduce_lr_factor\": 0.5,\n",
        "    \"reduce_lr_patience\": 3,\n",
        "    \"weight_decay\": 0.0001,\n",
        "    \"epochs\": 50\n",
        "}\n",
        "\n",
        "# ============================\n",
        "# 5. GRADIENT REVERSAL\n",
        "# ============================\n",
        "@tf.custom_gradient\n",
        "def grad_reverse(x, lambda_):\n",
        "    def grad(dy):\n",
        "        return -lambda_ * dy, None\n",
        "    return x, grad\n",
        "\n",
        "class GradientReversalLayer(layers.Layer):\n",
        "    def __init__(self, lambda_):\n",
        "        super().__init__()\n",
        "        self.lambda_ = lambda_\n",
        "    def call(self, x):\n",
        "        return grad_reverse(x, self.lambda_)\n",
        "\n",
        "# ============================\n",
        "# 6. MODEL BUILDERS\n",
        "# ============================\n",
        "def build_baseline_model():\n",
        "    inputs = layers.Input(shape=(96,96,3))\n",
        "    x = layers.Conv2D(32,3,activation='relu')(inputs)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(64,3,activation='relu')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128,activation='relu')(x)\n",
        "    x = layers.Dropout(config[\"dropout_rate\"])(x)\n",
        "    out = layers.Dense(1)(x)\n",
        "    opt = optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
        "    model = models.Model(inputs, out)\n",
        "    model.compile(optimizer=opt, loss=\"mae\", metrics=[\"mae\"])\n",
        "    return model\n",
        "\n",
        "def build_debiased_model():\n",
        "    inputs = layers.Input(shape=(96,96,3))\n",
        "    x = layers.Conv2D(32,3,activation='relu')(inputs)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(64,3,activation='relu')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    features = layers.Dense(128,activation='relu')(x)\n",
        "    features = layers.Dropout(config[\"dropout_rate\"])(features)\n",
        "    age_out = layers.Dense(1,name=\"age\")(features)\n",
        "    grl = GradientReversalLayer(config[\"adv_loss_weight\"])(features)\n",
        "    race_out = layers.Dense(5,activation='softmax',name=\"race\")(grl)\n",
        "\n",
        "    opt = optimizers.Adam(learning_rate=config[\"learning_rate\"], decay=config[\"weight_decay\"])\n",
        "    model = models.Model(inputs, [age_out, race_out])\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss={\"age\":\"mae\",\"race\":\"sparse_categorical_crossentropy\"},\n",
        "        loss_weights={\"age\":1.0,\"race\":config[\"adv_loss_weight\"]}\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ============================\n",
        "# 7. FAIRNESS EVALUATION\n",
        "# ============================\n",
        "def evaluate_model(model, debiased=False):\n",
        "    if debiased:\n",
        "        preds_age,_ = model.predict(X_test, verbose=0)\n",
        "    else:\n",
        "        preds_age = model.predict(X_test, verbose=0)\n",
        "    preds_age = preds_age.flatten()\n",
        "\n",
        "    overall_mae = np.mean(np.abs(preds_age - y_age_test))\n",
        "    group_errors = defaultdict(list)\n",
        "    for p,t,r,g in zip(preds_age, y_age_test, y_race_test, y_gender_test):\n",
        "        key = f\"{r}_{g}\"\n",
        "        group_errors[key].append(abs(p-t))\n",
        "    group_maes = {k: np.mean(v) for k,v in group_errors.items()}\n",
        "    worst_group_mae = max(group_maes.values())\n",
        "    bias_gap = worst_group_mae - min(group_maes.values())\n",
        "    mean_group_mae = np.mean(list(group_maes.values()))\n",
        "    return {\n",
        "        \"overall_mae\":overall_mae,\n",
        "        \"worst_group_mae\":worst_group_mae,\n",
        "        \"bias_gap\":bias_gap,\n",
        "        \"mean_group_mae\":mean_group_mae\n",
        "    }\n",
        "\n",
        "# ============================\n",
        "# 8. CALLBACKS\n",
        "# ============================\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "def get_callbacks():\n",
        "    return [\n",
        "        callbacks.EarlyStopping(\n",
        "            monitor=\"val_mae\",\n",
        "            patience=config[\"early_stop_patience\"],\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        callbacks.ReduceLROnPlateau(\n",
        "            monitor=\"val_mae\",\n",
        "            factor=config[\"reduce_lr_factor\"],\n",
        "            patience=config[\"reduce_lr_patience\"],\n",
        "            min_lr=1e-6\n",
        "        ),\n",
        "        WandbCallback(save_model=False)\n",
        "    ]\n",
        "\n",
        "# ============================\n",
        "# 9. MULTI-SEED W&B TRAINING\n",
        "# ============================\n",
        "seeds = [0,1,2,3,4]\n",
        "results = []\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "\n",
        "    # --- Baseline ---\n",
        "    wandb.init(\n",
        "        project=\"age-debias-utkface\",\n",
        "        name=f\"baseline-seed{seed}\",\n",
        "        config=config, reinit=True\n",
        "    )\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    baseline = build_baseline_model()\n",
        "    baseline.fit(\n",
        "        X_train, y_age_train,\n",
        "        validation_data=(X_val, y_age_val),\n",
        "        epochs=config[\"epochs\"],\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        callbacks=get_callbacks(),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    metrics = evaluate_model(baseline, debiased=False)\n",
        "    wandb.log(metrics)\n",
        "    results.append({\"seed\":seed, \"model\":\"baseline\", **metrics})\n",
        "    wandb.finish()\n",
        "\n",
        "    # --- Debiased ---\n",
        "    wandb.init(\n",
        "        project=\"age-debias-utkface\",\n",
        "        name=f\"debiased-seed{seed}\",\n",
        "        config=config, reinit=True\n",
        "    )\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    debiased = build_debiased_model()\n",
        "    debiased.fit(\n",
        "        X_train,\n",
        "        {\"age\":y_age_train, \"race\":y_race_train},\n",
        "        validation_data=(X_val, {\"age\":y_age_val, \"race\":y_race_val}),\n",
        "        epochs=config[\"epochs\"],\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        callbacks=get_callbacks(),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    metrics = evaluate_model(debiased, debiased=True)\n",
        "    wandb.log(metrics)\n",
        "    results.append({\"seed\":seed, \"model\":\"debiased\", **metrics})\n",
        "    wandb.finish()\n",
        "\n",
        "# ============================\n",
        "# 10. FINAL SUMMARY\n",
        "# ============================\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"multi_seed_results.csv\", index=False)\n",
        "print(df)\n",
        "\n",
        "for m in [\"baseline\",\"debiased\"]:\n",
        "    sub = df[df[\"model\"]==m]\n",
        "    print(f\"\\n{m.upper()}:\")\n",
        "    for metric in [\"overall_mae\",\"worst_group_mae\",\"bias_gap\",\"mean_group_mae\"]:\n",
        "        print(f\"{metric}: {sub[metric].mean():.4f} Â± {sub[metric].std():.4f}\")\n",
        "\n",
        "b = df[df.model==\"baseline\"][\"bias_gap\"].values\n",
        "d = df[df.model==\"debiased\"][\"bias_gap\"].values\n",
        "t_stat,p_val = ttest_rel(b,d)\n",
        "print(f\"\\nPaired t-test on bias_gap: t={t_stat:.4f}, p={p_val:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqlq8TGNadON"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
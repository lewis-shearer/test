{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPey1dAqO394LaLa4UBTm2H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lewis-shearer/test/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "X8ngauF3aEJA",
        "outputId": "763ed597-10d1-439d-c813-03d215ff6d08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'utkface-new' dataset.\n",
            "Dataset path: /kaggle/input/utkface-new/UTKFace\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">base_0</strong> at: <a href='https://wandb.ai/lshearer2957-self/age-debias-utkface/runs/lo4myi45' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-debias-utkface/runs/lo4myi45</a><br> View project at: <a href='https://wandb.ai/lshearer2957-self/age-debias-utkface' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-debias-utkface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260220_123906-lo4myi45/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260220_124034-56esjw21</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lshearer2957-self/age-debias-utkface/runs/56esjw21' target=\"_blank\">base_0</a></strong> to <a href='https://wandb.ai/lshearer2957-self/age-debias-utkface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lshearer2957-self/age-debias-utkface' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-debias-utkface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lshearer2957-self/age-debias-utkface/runs/56esjw21' target=\"_blank\">https://wandb.ai/lshearer2957-self/age-debias-utkface/runs/56esjw21</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 76ms/step - loss: 14.8681 - mae: 14.8681 - val_loss: 11.0577 - val_mae: 11.0577 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 36ms/step - loss: 10.2619 - mae: 10.2619 - val_loss: 8.6209 - val_mae: 8.6209 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 35ms/step - loss: 9.1845 - mae: 9.1845 - val_loss: 8.4163 - val_mae: 8.4163 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 36ms/step - loss: 8.6356 - mae: 8.6356 - val_loss: 7.6595 - val_mae: 7.6595 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 36ms/step - loss: 8.2742 - mae: 8.2742 - val_loss: 7.4106 - val_mae: 7.4106 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 36ms/step - loss: 7.8139 - mae: 7.8139 - val_loss: 7.4440 - val_mae: 7.4440 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 36ms/step - loss: 7.4531 - mae: 7.4531 - val_loss: 8.5420 - val_mae: 8.5420 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 35ms/step - loss: 7.2192 - mae: 7.2192 - val_loss: 7.3536 - val_mae: 7.3536 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 32ms/step - loss: 6.9704 - mae: 6.9704 - val_loss: 7.0932 - val_mae: 7.0932 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 33ms/step - loss: 6.6819 - mae: 6.6819 - val_loss: 7.6950 - val_mae: 7.6950 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 31ms/step - loss: 6.5092 - mae: 6.5092 - val_loss: 7.2656 - val_mae: 7.2656 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 37ms/step - loss: 6.2654 - mae: 6.2654 - val_loss: 6.9459 - val_mae: 6.9459 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 32ms/step - loss: 6.0553 - mae: 6.0553 - val_loss: 7.6474 - val_mae: 7.6474 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 32ms/step - loss: 5.9731 - mae: 5.9731 - val_loss: 6.9740 - val_mae: 6.9740 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 33ms/step - loss: 5.8480 - mae: 5.8480 - val_loss: 7.0981 - val_mae: 7.0981 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 34ms/step - loss: 5.5597 - mae: 5.5597 - val_loss: 6.9023 - val_mae: 6.9023 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 32ms/step - loss: 5.3488 - mae: 5.3488 - val_loss: 6.9455 - val_mae: 6.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 34ms/step - loss: 5.1907 - mae: 5.1907 - val_loss: 6.8991 - val_mae: 6.8991 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m1037/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 34ms/step - loss: 5.0838 - mae: 5.0838 - val_loss: 7.1030 - val_mae: 7.1030 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m1036/1037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.1014 - mae: 5.1014"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import ttest_rel\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import wandb\n",
        "from wandb.keras import WandbMetricsLogger\n",
        "import kagglehub\n",
        "\n",
        "# ============================\n",
        "# 1. DOWNLOAD DATA\n",
        "# ============================\n",
        "path = kagglehub.dataset_download(\"jangedoo/utkface-new\")\n",
        "data_dir = os.path.join(path, \"UTKFace\")\n",
        "print(\"Dataset path:\", data_dir)\n",
        "\n",
        "# ============================\n",
        "# 2. REPRODUCIBILITY\n",
        "# ============================\n",
        "def set_seed(seed):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "# ============================\n",
        "# 3. LOAD FILENAMES AND LABELS\n",
        "# ============================\n",
        "def parse_filename(fname):\n",
        "    parts = fname.split(\"_\")\n",
        "    return int(parts[0]), int(parts[1]), int(parts[2])\n",
        "\n",
        "all_files = []\n",
        "all_ages = []\n",
        "all_genders = []\n",
        "all_races = []\n",
        "\n",
        "for fname in os.listdir(data_dir):\n",
        "    if fname.lower().endswith(\".jpg\"):\n",
        "        try:\n",
        "            age, gender, race = parse_filename(fname)\n",
        "            all_files.append(os.path.join(data_dir, fname))\n",
        "            all_ages.append(age)\n",
        "            all_genders.append(gender)\n",
        "            all_races.append(race)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "all_files = np.array(all_files)\n",
        "all_ages = np.array(all_ages, dtype=np.float32)\n",
        "all_genders = np.array(all_genders)\n",
        "all_races = np.array(all_races)\n",
        "\n",
        "# ============================\n",
        "# 4. TRAIN/VAL/TEST SPLIT\n",
        "# ============================\n",
        "X_train_files, X_temp_files, y_age_train, y_age_temp, y_gender_train, y_gender_temp, y_race_train, y_race_temp = train_test_split(\n",
        "    all_files, all_ages, all_genders, all_races,\n",
        "    test_size=0.3, stratify=all_races, random_state=42\n",
        ")\n",
        "\n",
        "X_val_files, X_test_files, y_age_val, y_age_test, y_gender_val, y_gender_test, y_race_val, y_race_test = train_test_split(\n",
        "    X_temp_files, y_age_temp, y_gender_temp, y_race_temp,\n",
        "    test_size=0.5, stratify=y_race_temp, random_state=42\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 5. HYPERPARAMETERS\n",
        "# ============================\n",
        "config = {\n",
        "    \"adv_loss_weight\": 0.01,\n",
        "    \"batch_size\": 16,  # smaller to reduce memory\n",
        "    \"dropout_rate\": 0.25,\n",
        "    \"early_stop_patience\": 5,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"reduce_lr_factor\": 0.5,\n",
        "    \"reduce_lr_patience\": 3,\n",
        "    \"weight_decay\": 0.0001,\n",
        "    \"epochs\": 50\n",
        "}\n",
        "\n",
        "# ============================\n",
        "# 6. GRADIENT REVERSAL\n",
        "# ============================\n",
        "@tf.custom_gradient\n",
        "def grad_reverse(x, lambda_):\n",
        "    def grad(dy):\n",
        "        return -lambda_ * dy, None\n",
        "    return x, grad\n",
        "\n",
        "class GradientReversalLayer(layers.Layer):\n",
        "    def __init__(self, lambda_):\n",
        "        super().__init__()\n",
        "        self.lambda_ = lambda_\n",
        "    def call(self, x):\n",
        "        return grad_reverse(x, self.lambda_)\n",
        "\n",
        "# ============================\n",
        "# 7. DATA GENERATOR\n",
        "# ============================\n",
        "def data_generator(file_list, y_age, y_race=None):\n",
        "    while True:\n",
        "        for i in range(0, len(file_list), config[\"batch_size\"]):\n",
        "            batch_files = file_list[i:i+config[\"batch_size\"]]\n",
        "            batch_images = []\n",
        "            batch_ages = []\n",
        "            batch_races = [] if y_race is not None else None\n",
        "            for j, f in enumerate(batch_files):\n",
        "                img = Image.open(f).resize((96,96))\n",
        "                img = np.array(img)/255.0\n",
        "                batch_images.append(img)\n",
        "                batch_ages.append(y_age[i+j])\n",
        "                if y_race is not None:\n",
        "                    batch_races.append(y_race[i+j])\n",
        "            batch_images = np.array(batch_images, dtype=np.float32)\n",
        "            batch_ages = np.array(batch_ages, dtype=np.float32)\n",
        "            if y_race is not None:\n",
        "                batch_races = np.array(batch_races)\n",
        "                yield batch_images, {\"age\": batch_ages, \"race\": batch_races}\n",
        "            else:\n",
        "                yield batch_images, batch_ages\n",
        "\n",
        "# Steps per epoch\n",
        "train_steps = len(X_train_files) // config[\"batch_size\"]\n",
        "val_steps = len(X_val_files) // config[\"batch_size\"]\n",
        "\n",
        "# ============================\n",
        "# 8. MODEL BUILDERS\n",
        "# ============================\n",
        "def build_baseline_model():\n",
        "    inputs = layers.Input(shape=(96,96,3))\n",
        "    x = layers.Conv2D(32,3,activation='relu')(inputs)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(64,3,activation='relu')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128,activation='relu')(x)\n",
        "    x = layers.Dropout(config[\"dropout_rate\"])(x)\n",
        "    out = layers.Dense(1)(x)\n",
        "    opt = optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
        "    model = models.Model(inputs, out)\n",
        "    model.compile(optimizer=opt, loss=\"mae\", metrics=[\"mae\"])\n",
        "    return model\n",
        "\n",
        "def build_debiased_model():\n",
        "    inputs = layers.Input(shape=(96,96,3))\n",
        "    x = layers.Conv2D(32,3,activation='relu')(inputs)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(64,3,activation='relu')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    features = layers.Dense(128,activation='relu')(x)\n",
        "    features = layers.Dropout(config[\"dropout_rate\"])(features)\n",
        "    age_out = layers.Dense(1,name=\"age\")(features)\n",
        "    grl = GradientReversalLayer(config[\"adv_loss_weight\"])(features)\n",
        "    race_out = layers.Dense(5,activation='softmax',name=\"race\")(grl)\n",
        "\n",
        "    opt = optimizers.Adam(learning_rate=config[\"learning_rate\"], decay=config[\"weight_decay\"])\n",
        "    model = models.Model(inputs, [age_out, race_out])\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss={\"age\":\"mae\",\"race\":\"sparse_categorical_crossentropy\"},\n",
        "        loss_weights={\"age\":1.0,\"race\":config[\"adv_loss_weight\"]}\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ============================\n",
        "# 9. EVALUATION\n",
        "# ============================\n",
        "def evaluate_model(model, debiased=False):\n",
        "    if debiased:\n",
        "        preds_age,_ = model.predict(tf.data.Dataset.from_generator(\n",
        "            lambda: data_generator(X_test_files, y_age_test, y_race_test),\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(None,96,96,3), dtype=tf.float32),\n",
        "                {\n",
        "                    \"age\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
        "                    \"race\": tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "                }\n",
        "            )\n",
        "        ), steps=len(X_test_files)//config[\"batch_size\"])\n",
        "    else:\n",
        "        preds_age = model.predict(tf.data.Dataset.from_generator(\n",
        "            lambda: data_generator(X_test_files, y_age_test),\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(None,96,96,3), dtype=tf.float32),\n",
        "                tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
        "            )\n",
        "        ), steps=len(X_test_files)//config[\"batch_size\"])\n",
        "    preds_age = preds_age.flatten()\n",
        "    overall_mae = np.mean(np.abs(preds_age - y_age_test))\n",
        "    group_errors = defaultdict(list)\n",
        "    for p,t,r,g in zip(preds_age, y_age_test, y_race_test, y_gender_test):\n",
        "        key = f\"{r}_{g}\"\n",
        "        group_errors[key].append(abs(p-t))\n",
        "    group_maes = {k: np.mean(v) for k,v in group_errors.items()}\n",
        "    worst_group_mae = max(group_maes.values())\n",
        "    bias_gap = worst_group_mae - min(group_maes.values())\n",
        "    mean_group_mae = np.mean(list(group_maes.values()))\n",
        "    return {\n",
        "        \"overall_mae\":overall_mae,\n",
        "        \"worst_group_mae\":worst_group_mae,\n",
        "        \"bias_gap\":bias_gap,\n",
        "        \"mean_group_mae\":mean_group_mae\n",
        "    }\n",
        "\n",
        "# ============================\n",
        "# 10. CALLBACKS\n",
        "# ============================\n",
        "def get_callbacks(monitor=\"val_mae\"):\n",
        "    return [\n",
        "        callbacks.EarlyStopping(monitor=monitor, patience=config[\"early_stop_patience\"], mode=\"min\", restore_best_weights=True),\n",
        "        callbacks.ReduceLROnPlateau(monitor=monitor, factor=config[\"reduce_lr_factor\"], patience=config[\"reduce_lr_patience\"], min_lr=1e-6),\n",
        "        WandbMetricsLogger(log_freq='epoch') # Replaced WandbCallback\n",
        "    ]\n",
        "\n",
        "# ============================\n",
        "# 11. MULTI-SEED TRAINING\n",
        "# ============================\n",
        "seeds = [0,1,2,3,4]\n",
        "results = []\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # --- Baseline ---\n",
        "    wandb.init(project=\"age-debias-utkface\", name=f\"base_{seed}\", config=config, reinit=True)\n",
        "    baseline = build_baseline_model()\n",
        "    baseline.fit(\n",
        "        tf.data.Dataset.from_generator(lambda: data_generator(X_train_files, y_age_train),\n",
        "                                       output_signature=(tf.TensorSpec(shape=(None,96,96,3), dtype=tf.float32),\n",
        "                                                         tf.TensorSpec(shape=(None,), dtype=tf.float32))\n",
        "                                      ).prefetch(tf.data.AUTOTUNE),\n",
        "        validation_data=tf.data.Dataset.from_generator(lambda: data_generator(X_val_files, y_age_val),\n",
        "                                                       output_signature=(tf.TensorSpec(shape=(None,96,96,3), dtype=tf.float32),\n",
        "                                                                         tf.TensorSpec(shape=(None,), dtype=tf.float32))\n",
        "                                                      ).prefetch(tf.data.AUTOTUNE),\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=val_steps,\n",
        "        epochs=config[\"epochs\"],\n",
        "        callbacks=get_callbacks(),\n",
        "        verbose=1\n",
        "    )\n",
        "    metrics = evaluate_model(baseline, debiased=False)\n",
        "    wandb.log(metrics)\n",
        "    results.append({\"seed\":seed, \"model\":\"baseline\", **metrics})\n",
        "    wandb.finish()\n",
        "\n",
        "    # --- Debiased ---\n",
        "    wandb.init(project=\"age-debias-utkface\", name=f\"deb_{seed}\", config=config, reinit=True)\n",
        "    tf.keras.backend.clear_session()\n",
        "    debiased = build_debiased_model()\n",
        "    debiased.fit(\n",
        "        tf.data.Dataset.from_generator(lambda: data_generator(X_train_files, y_age_train, y_race_train),\n",
        "                                       output_signature=(\n",
        "                                           tf.TensorSpec(shape=(None,96,96,3), dtype=tf.float32),\n",
        "                                           {\n",
        "                                               \"age\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
        "                                               \"race\": tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "                                           }\n",
        "                                       )).prefetch(tf.data.AUTOTUNE),\n",
        "        validation_data=tf.data.Dataset.from_generator(lambda: data_generator(X_val_files, y_age_val, y_race_val),\n",
        "                                                       output_signature=(\n",
        "                                                           tf.TensorSpec(shape=(None,96,96,3), dtype=tf.float32),\n",
        "                                                           {\n",
        "                                                               \"age\": tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
        "                                                               \"race\": tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "                                                           }\n",
        "                                                       )).prefetch(tf.data.AUTOTUNE),\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=val_steps,\n",
        "        epochs=config[\"epochs\"],\n",
        "        callbacks=get_callbacks(monitor=\"val_age_mae\"),\n",
        "        verbose=1\n",
        "    )\n",
        "    metrics = evaluate_model(debiased, debiased=True)\n",
        "    wandb.log(metrics)\n",
        "    results.append({\"seed\":seed, \"model\":\"debiased\", **metrics})\n",
        "    wandb.finish()\n",
        "\n",
        "# ============================\n",
        "# 12. FINAL SUMMARY\n",
        "# ============================\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"multi_seed_results.csv\", index=False)\n",
        "print(df)\n",
        "\n",
        "for m in [\"baseline\",\"debiased\"]:\n",
        "    sub = df[df[\"model\"]==m]\n",
        "    print(f\"\\n{m.upper()}:\")\n",
        "    for metric in [\"overall_mae\",\"worst_group_mae\",\"bias_gap\",\"mean_group_mae\"]:\n",
        "        print(f\"{metric}: {sub[metric].mean():.4f} \\u00b1 {sub[metric].std():.4f}\")\n",
        "\n",
        "# Paired t-test\n",
        "b = df[df.model==\"baseline\"][\"bias_gap\"].values\n",
        "d = df[df.model==\"debiased\"][\"bias_gap\"].values\n",
        "t_stat,p_val = ttest_rel(b,d)\n",
        "print(f\"\\nPaired t-test on bias_gap: t={t_stat:.4f}, p={p_val:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqlq8TGNadON"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}